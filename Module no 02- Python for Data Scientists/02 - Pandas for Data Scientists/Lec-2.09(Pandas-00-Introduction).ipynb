{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6686c3f",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<h1 align=\"center\">Introduction to Data Analyst and Data Science for beginners</h1>\n",
    "<h1 align=\"center\">Lecture no 2.09(Pandas-00)</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Ehtisham Sadiq</div></h3>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc3b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b694ef9",
   "metadata": {},
   "source": [
    "# _Python_Pandas_Introduction.ipynb_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091eff40",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"700\" height=\"700\"  src=\"images/pandas-apps.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5fae3",
   "metadata": {},
   "source": [
    "> **Pandas is an open source python library built on top of numpy and provides easy to use data structures and data analysis tools. Pandas has derived its name from panel data system and was developed by wes mckinney in 2008.**\n",
    "\n",
    "> **Data scientists use pandas for performing various data science tasks starting from downloading, opening, reading and writing files of different file formats like csv, excel, json, html and so on. They load the data set into its data structure called data frame.**\n",
    "\n",
    "> **A Pandas Dataframe is a 2-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.**\n",
    "\n",
    "> **After the data is loaded in a data frame the data scientists perform a various data manipulation tasks like filtering and modifying data based on multiple conditions cutting, splitting, merging, sorting, scaling, pivoting and aggregating of data.**\n",
    "\n",
    "> **Data cleaning is done to enhance the data accuracy and integrity by identifying and removing null values, duplicates and outliers.**\n",
    "\n",
    "> **Data wrangling actually transforms the data structurally to appropriate format and makes it ready to be used by the machine learning engineers so that they can apply appropriate machine learning models or algorithm on that data set for training validating and testing purposes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5596548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "930e2e5c",
   "metadata": {},
   "source": [
    "## Learning Agenda of this Notebook:\n",
    "- What is Pandas and how is it used in AI?\n",
    "- Key features of Pandas\n",
    "- Data Types in Pandas\n",
    "- What does Pandas deal with?\n",
    "- Creating Series and Dataframes in Pandas\n",
    "- Data Handling with Pandas\n",
    "  - Practice Exercise I\n",
    "  - Practice Exercise II\n",
    "- All Statistical functions in Pandas\n",
    "- Input/Output Operations\n",
    "- Aggregation & Grouping\n",
    "  - Practice Exercise\n",
    "- Merging, Joining and Concatenation\n",
    "  - Practice Exercise\n",
    "- How To Perform Data Visualization with Pandas\n",
    "- Exercise I\n",
    "- Exercise II\n",
    "- Pandas's Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10143023",
   "metadata": {},
   "source": [
    "### Data Structures in Pandas:\n",
    "<img src=\"https://www.databricks.com/wp-content/uploads/2019/03/pandas1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95ae3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d881437",
   "metadata": {},
   "source": [
    ">-  **A Pandas Dataframe is a 2-dimensional labeled data structure (like SQL table) with heterogeneously typed columns, having both a row and a column index.**\n",
    ">-  **In short Pandas is a Software Libarary in Computer Programming and it is written for the Python Programming Language its work to do `data analysis and manipulation.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a611a7",
   "metadata": {},
   "source": [
    "## So, what is Pandas and how is it used in AI?\n",
    "\n",
    "Artificial Intelligence is about executing machine learning algorithms on products that we use every day. Any ML algorithm, for it to be effective, needs the following prerequisite steps to be done.\n",
    "- `Data Collection` – Conducting opinion Surveys, scraping the internet, etc.\n",
    "- `Data Handling` – Viewing data as a table, performing cleaning activities like checking for spellings, removal of blanks and wrong cases, removal of invalid values from data, etc.\n",
    "- `Data Visualization` – plotting appealing graphs, so anyone who looks at the data can know what story the data tells us.\n",
    "- `Pandas` – short for `Panel Data` (A panel is a 3D container of data) – is a library in python which contains in-built functions to clean, transform, manipulate, visualize and analyze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d09ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4573e9",
   "metadata": {},
   "source": [
    "## Key Features of Pandas\n",
    "<img src=\"images/Python-Pandas-Features.webp\" height=600px width=600px>\n",
    "\n",
    "\n",
    "- It has a fast and efficient DataFrame object with the default and customized indexing.\n",
    "- Used for reshaping and pivoting of the data sets.\n",
    "- Group by data for aggregations and transformations.\n",
    "- It is used for data alignment and integration of the missing data.\n",
    "- Provide the functionality of Time Series.\n",
    "- Process a variety of data sets in different formats like matrix data, tabular heterogeneous, time series.\n",
    "- Handle multiple operations of the data sets such as subsetting, slicing, filtering, groupBy, re-ordering, and re-shaping.\n",
    "- It integrates with the other libraries such as SciPy, and scikit-learn.\n",
    "- Provides fast performance, and If you want to speed it, even more, you can use the Cython."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ceb96",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "A data type is used by a programming language to understand how to store and manipulate data.\n",
    "- `int` : Integer number, eg: 10, 12\n",
    "- `float` : Floating point number, eg: 100.2, 3.1415\n",
    "- `bool` : True/False value\n",
    "- `object` : Test, non-numeric, or a combination of text and non-numeric values, eg: Apple\n",
    "- `DateTime` : Date and time values\n",
    "- `category` : A finite list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64c5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "092dbfa8",
   "metadata": {},
   "source": [
    "## What does Pandas deal with?\n",
    "There are two major categories of data that you can come across while doing data analysis.\n",
    "- One dimensional data\n",
    "- Two-dimensional data\n",
    "\n",
    "These data can be of any data type. Character, number or even an object.\n",
    "\n",
    "> **Series in Pandas is one-dimensional data, and data frames are 2-dimensional data. A series can hold only a single data type, whereas a data frame is meant to contain more than one data type.**\n",
    "\n",
    "![](images/dataframe.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6983313",
   "metadata": {},
   "source": [
    "**In the example shown above, `Name` is a `series` and it is of the datatype – `Object` and it is treated as a character array. `Age` is another series and it is of the type – `Integer`. Third is the `Marks` is the third series and it is of the type `Integer` again.  The individual Series are one dimensional and hold only one data type. However, the `dataframe` as a whole contains more than 2 dimensions and is `heterogeneous` in nature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a267b9",
   "metadata": {},
   "source": [
    "## Creating Series & data frames in python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466edb52",
   "metadata": {},
   "source": [
    "#### Creating a simple Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41385b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.4.2', ['/home/dell/.local/lib/python3.8/site-packages/pandas'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__, pd.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63690ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de967aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Ehtisham\n",
      "1         Ali\n",
      "2      Ayesha\n",
      "3         Dua\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#importing pandas library\n",
    "import pandas as pd\n",
    " \n",
    "#Creating a list\n",
    "name = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "\n",
    "#Creating a Series by passing list variable to Series() function of pandas \n",
    "name_series = pd.Series(name)\n",
    "\n",
    "#Printing Series\n",
    "print(name_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5df77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of name_Series is :  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Let’s check type of Series\n",
    "print(\"Type of name_Series is : \",type(name_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6578f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15c7058",
   "metadata": {},
   "source": [
    "#### Creating multiple series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda1d0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Series : \n",
      "0    Ehtisham\n",
      "1         Ali\n",
      "2      Ayesha\n",
      "3         Dua\n",
      "dtype: object\n",
      "Marks Series : \n",
      "0    91.5\n",
      "1    93.0\n",
      "2    80.0\n",
      "3    65.0\n",
      "dtype: float64\n",
      "Age Series : \n",
      "0    21\n",
      "1    18\n",
      "2    16\n",
      "3     6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "name = ['Ehtisham', 'Ali', 'Ayesha', 'Dua']\n",
    "marks = [91.5,93,80,65]\n",
    "age = [21,18,16,6]\n",
    "\n",
    "#Creating a Series by passing list variable to Series() function of pandas \n",
    "name_ser = pd.Series(name)\n",
    "marks_ser = pd.Series(marks)\n",
    "age_ser = pd.Series(age)\n",
    "\n",
    "#Printing Series\n",
    "print(\"Name Series : \", name_ser, sep=\"\\n\")\n",
    "print(\"Marks Series : \", marks_ser, sep=\"\\n\")\n",
    "print(\"Age Series : \", age_ser,sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6d90e",
   "metadata": {},
   "source": [
    "#### Creating Dataframe from multiple Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e5d7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing of DataFrame .... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ehtisham</td>\n",
       "      <td>91.5</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ali</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayesha</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dua</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Marks  Age\n",
       "0  Ehtisham   91.5   21\n",
       "1       Ali   93.0   18\n",
       "2    Ayesha   80.0   16\n",
       "3       Dua   65.0    6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a Series by passing list variable to Series() function of pandas \n",
    "name_ser = pd.Series(name)\n",
    "marks_ser = pd.Series(marks)\n",
    "age_ser = pd.Series(age)\n",
    "\n",
    "# Creating a Dictionary by passing series as values of dictionary\n",
    "dic = {'Name':name_ser,\n",
    "      'Marks':marks_ser,\n",
    "      'Age':age_ser\n",
    "      }\n",
    "\n",
    "# Create dataframe by passing dictionary to pd.DataFrame function of pandas\n",
    "df = pd.DataFrame(dic)\n",
    "print(\"Printing of DataFrame .... \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0b386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02c29ac",
   "metadata": {},
   "source": [
    "#### How to add new column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9bc933e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing of DataFrame .... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Age</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ehtisham</td>\n",
       "      <td>91.5</td>\n",
       "      <td>21</td>\n",
       "      <td>Lahore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ali</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18</td>\n",
       "      <td>Okara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayesha</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Okara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dua</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Okara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  Marks  Age Address\n",
       "0  Ehtisham   91.5   21  Lahore\n",
       "1       Ali   93.0   18   Okara\n",
       "2    Ayesha   80.0   16   Okara\n",
       "3       Dua   65.0    6   Okara"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = pd.Series(['Lahore','Okara','Okara','Okara'])\n",
    "##Creating new column in the dataframe by providing s Series created using list\n",
    "df['Address'] = address\n",
    "print(\"Printing of DataFrame .... \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bce7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f154a69f",
   "metadata": {},
   "source": [
    "## Data Handling with Pandas..\n",
    "\n",
    "- **Data Reading** : Reading from a csv or an excel – Pandas provide two functions – read_csv() and read_excel() to read data from a csv and an excel file respectively. Command can be used as follows.\n",
    "\n",
    "- **Viewing data** – Viewing data from a data frame can be done by three ways\n",
    " >- using the data frame’s name – returns the top and bottom 5 rows in the data frame.\n",
    " >- using dataframe.head() function\n",
    " >- using dataframe.tail() function\n",
    "\n",
    "- **Data Overview** : To see more details on the data frame, the `info()` function can be used. info() gives an idea about what datatype each series in a data frame points to.\n",
    "\n",
    "- The following functions are used to find the unique entries within a series/column in a data frame.\n",
    " >- datafame.unique() – returns the unique values\n",
    " >- dataframe.nunique() – returns the count of unique values\n",
    " >- dataframe.value_counts() – returns the frequency of each of the categories in the column\n",
    "\n",
    "- In our example, the titanic dataset contains a column called `Survived` which tells if the particular passenger survived the tragedy. Since this value could only be either 0 or 1, we can convert the data type from integer to object.\n",
    " >- `dataframe.astype()` is the function which lets us do the conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13227ab2",
   "metadata": {},
   "source": [
    "## Practice Questions Part 1: \n",
    "- Step 1. Import the necessary libraries.\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/u.user)\n",
    "- Step 3. Assign it to a variable called users and use the `user_id` as index\n",
    "- Step 4. See the first 25 entries\n",
    "- Step 5. See the last 10 entries\n",
    "- Step 6. What is the number of observations in the dataset?\n",
    "- Step 7. What is the number of columns in the dataset?\n",
    "- Step 8. Print the name of all the columns.\n",
    "- Step 9. How is the dataset indexed?\n",
    "- Step 10. What is the data type of each column?\n",
    "- Step 11. Print only the occupation column\n",
    "- Step 12. How many different occupations are in this dataset?\n",
    "- Step 13. What is the most frequent occupation?\n",
    "- Step 14. Summarize the DataFrame.\n",
    "- Step 15. Summarize all the columns\n",
    "- Step 16. Summarize only the occupation column\n",
    "- Step 17. What is the mean age of users?\n",
    "- Step 18. What is the age with least occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e6ff18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age gender  occupation zip_code\n",
       "0        1   24      M  technician    85711\n",
       "1        2   53      F       other    94043\n",
       "2        3   23      M      writer    32067\n",
       "3        4   24      M  technician    43537\n",
       "4        5   33      F       other    15213"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# data reading\n",
    "url = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/u.user\"\n",
    "users = pd.read_csv(url, delimiter=\"|\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a974f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender  occupation zip_code\n",
       "user_id                                 \n",
       "1         24      M  technician    85711\n",
       "2         53      F       other    94043\n",
       "3         23      M      writer    32067\n",
       "4         24      M  technician    43537\n",
       "5         33      F       other    15213"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 03\n",
    "# First Method\n",
    "users = pd.read_csv(url, delimiter=\"|\", index_col='user_id')\n",
    "users.head()\n",
    "\n",
    "\n",
    "# Second method\n",
    "# users.set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cf35a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>91344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>05201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>01002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>90703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>30329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>06405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>29206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "      <td>55106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>educator</td>\n",
       "      <td>97301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>10309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>06355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>37212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>librarian</td>\n",
       "      <td>02138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>homemaker</td>\n",
       "      <td>95660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>30068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>40206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>artist</td>\n",
       "      <td>48197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21</td>\n",
       "      <td>F</td>\n",
       "      <td>artist</td>\n",
       "      <td>94533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>55107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender     occupation zip_code\n",
       "user_id                                    \n",
       "1         24      M     technician    85711\n",
       "2         53      F          other    94043\n",
       "3         23      M         writer    32067\n",
       "4         24      M     technician    43537\n",
       "5         33      F          other    15213\n",
       "6         42      M      executive    98101\n",
       "7         57      M  administrator    91344\n",
       "8         36      M  administrator    05201\n",
       "9         29      M        student    01002\n",
       "10        53      M         lawyer    90703\n",
       "11        39      F          other    30329\n",
       "12        28      F          other    06405\n",
       "13        47      M       educator    29206\n",
       "14        45      M      scientist    55106\n",
       "15        49      F       educator    97301\n",
       "16        21      M  entertainment    10309\n",
       "17        30      M     programmer    06355\n",
       "18        35      F          other    37212\n",
       "19        40      M      librarian    02138\n",
       "20        42      F      homemaker    95660\n",
       "21        26      M         writer    30068\n",
       "22        25      M         writer    40206\n",
       "23        30      F         artist    48197\n",
       "24        21      F         artist    94533\n",
       "25        39      M       engineer    55107"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 04\n",
    "users.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed2ff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>engineer</td>\n",
       "      <td>22902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>doctor</td>\n",
       "      <td>66221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>other</td>\n",
       "      <td>32789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>98072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>38</td>\n",
       "      <td>F</td>\n",
       "      <td>technician</td>\n",
       "      <td>55038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age gender     occupation zip_code\n",
       "user_id                                    \n",
       "934       61      M       engineer    22902\n",
       "935       42      M         doctor    66221\n",
       "936       24      M          other    32789\n",
       "937       48      M       educator    98072\n",
       "938       38      F     technician    55038\n",
       "939       26      F        student    33319\n",
       "940       32      M  administrator    02215\n",
       "941       20      M        student    97229\n",
       "942       48      F      librarian    78209\n",
       "943       22      M        student    77841"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 05\n",
    "users.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a39257dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 943 entries, 1 to 943\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   age         943 non-null    int64 \n",
      " 1   gender      943 non-null    object\n",
      " 2   occupation  943 non-null    object\n",
      " 3   zip_code    943 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 36.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Task no 06\n",
    "users.shape\n",
    "# or \n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "705bc5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users.shape :  (943, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'occupation', 'zip_code'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 07 & 08\n",
    "print(\"users.shape : \",users.shape)\n",
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62554c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,\n",
       "            ...\n",
       "            934, 935, 936, 937, 938, 939, 940, 941, 942, 943],\n",
       "           dtype='int64', name='user_id', length=943)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 09\n",
    "users.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e4ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edf8934e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "gender        object\n",
       "occupation    object\n",
       "zip_code      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 10\n",
    "users.dtypes\n",
    " \n",
    "#     or \n",
    "# users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7d11018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1         technician\n",
       "2              other\n",
       "3             writer\n",
       "4         technician\n",
       "5              other\n",
       "           ...      \n",
       "939          student\n",
       "940    administrator\n",
       "941          student\n",
       "942        librarian\n",
       "943          student\n",
       "Name: occupation, Length: 943, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 11\n",
    "users['occupation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32e2a38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technician', 'other', 'writer', 'executive', 'administrator',\n",
       "       'student', 'lawyer', 'educator', 'scientist', 'entertainment',\n",
       "       'programmer', 'librarian', 'homemaker', 'artist', 'engineer',\n",
       "       'marketing', 'none', 'healthcare', 'retired', 'salesman', 'doctor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 12\n",
    "# First method\n",
    "users['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "452c95c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second method\n",
    "users['occupation'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb8d5ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student          196\n",
       "other            105\n",
       "educator          95\n",
       "administrator     79\n",
       "engineer          67\n",
       "programmer        66\n",
       "librarian         51\n",
       "writer            45\n",
       "executive         32\n",
       "scientist         31\n",
       "artist            28\n",
       "technician        27\n",
       "marketing         26\n",
       "entertainment     18\n",
       "healthcare        16\n",
       "retired           14\n",
       "lawyer            12\n",
       "salesman          12\n",
       "none               9\n",
       "homemaker          7\n",
       "doctor             7\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third method\n",
    "users['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bc774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46abf1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 13\n",
    "users['occupation'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed371e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>943.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.051962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.192740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age\n",
       "count  943.000000\n",
       "mean    34.051962\n",
       "std     12.192740\n",
       "min      7.000000\n",
       "25%     25.000000\n",
       "50%     31.000000\n",
       "75%     43.000000\n",
       "max     73.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 14\n",
    "users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "235d3de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>943</td>\n",
       "      <td>943</td>\n",
       "      <td>943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>55414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>670</td>\n",
       "      <td>196</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.051962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.192740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>73.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age gender occupation zip_code\n",
       "count   943.000000    943        943      943\n",
       "unique         NaN      2         21      795\n",
       "top            NaN      M    student    55414\n",
       "freq           NaN    670        196        9\n",
       "mean     34.051962    NaN        NaN      NaN\n",
       "std      12.192740    NaN        NaN      NaN\n",
       "min       7.000000    NaN        NaN      NaN\n",
       "25%      25.000000    NaN        NaN      NaN\n",
       "50%      31.000000    NaN        NaN      NaN\n",
       "75%      43.000000    NaN        NaN      NaN\n",
       "max      73.000000    NaN        NaN      NaN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 15\n",
    "users.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b56d54c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         943\n",
       "unique         21\n",
       "top       student\n",
       "freq          196\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 16\n",
    "users['occupation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7a73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d32e039f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.05196182396607"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 17\n",
    "users['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56add5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task no 18\n",
    "users['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f014425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498ee523",
   "metadata": {},
   "source": [
    "## Practice Questions Part 2:\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Euro_2012_stats_TEAM.csv)\n",
    "- Step 3. Assign it to a variable called `euro12`.\n",
    "- Step 4. Select only the Goal column.\n",
    "- Step 5. How many team participated in the Euro2012?(value_counts/shape)\n",
    "- Step 6. What is the number of columns in the dataset?(shape/info)\n",
    "- Step 7. View only the columns Team, Yellow Cards and Red Cards and assign them to a dataframe called discipline\n",
    "- Step 8. Sort the teams by Red Cards, then to Yellow Cards(Hint: sort_values)\n",
    "- Step 9. Calculate the mean Yellow Cards given per Team(Hint: round())\n",
    "- Step 10. Filter teams that scored more than 6 goals\n",
    "- Step 11. Select the teams that start with G(Hint : str.startswith('G'))\n",
    "- Step 12. Select the first 7 columns and all the rows(Hint: iloc())\n",
    "- Step 13. Select all columns except the last 3.(Hint: iloc())\n",
    "- Step 14. Presents/shows only the Shooting Accuracy from England, Italy and Russia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69a65628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # euro12.loc[), ['Team','Shooting Accuracy']]\n",
    "# euro12.loc[euro12.Team.isin(['England', 'Italy', 'Russia']), ['Team','Shooting Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5d730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e62cb2f",
   "metadata": {},
   "source": [
    "## All statistical functions\n",
    "- `count()` : Returns the number of times an element/data has occurred (non-null)\n",
    "- `sum()`\t: Returns sum of all values\n",
    "- `mean()` : Returns the average of all values\n",
    "- `median()` : Returns the median of all values\n",
    "- `mode()` : Returns the mode\n",
    "- `std()`\t: Returns the standard deviation\n",
    "- `min()`\t: Returns the minimum of all values\n",
    "- `max()`\t: Returns the maximum of all values\n",
    "- `abs()`\t: Returns the absolute value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of elements in each column of dataframe \")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd9edb",
   "metadata": {},
   "source": [
    "## Input and Output\n",
    "\n",
    "- Often, you won’t be creating data but will be having it in some form, and you would want to import it to run your analysis on it. Fortunately, Pandas allows you to do this. Not only does it help in importing data, but you can also save your data in your desired format using Pandas.\n",
    "- The below table shows the formats supported by Pandas, the function to read files using Pandas, and the function to write files.\n",
    "|Input |type      |\tReader\tWriter |\n",
    "|------|----------|----------------|\n",
    "|CSV   |read_csv  |  to_csv        |\n",
    "|JSON  |read_json | to_json\n",
    "|HTML  |read_html |to_html\n",
    "|Excel |read_excel|to_excel\n",
    "|SAS   |read_sas  |–\n",
    "|Python|Pickle    |\tread_pickle\tto_pickle\n",
    "|SQL   |read_sql  |to_sql\n",
    "|Google|Big Query | read_gbq\tto_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236bf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read input file\n",
    "df = pd.read_csv('datasets/psl.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da389b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a dataframe to CSV File\n",
    "data = {'Name':['Captain America', 'Iron Man', 'Hulk', 'Thor','Black Panther'],\n",
    "        'Rating':[100, 80, 84, 93, 90],\n",
    "        'Place':['USA','USA','USA','Asgard','Wakanda']}\n",
    "# Create dataframe from above dictionary\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"datasets/avengers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39481c21",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "- The aggregation function can be applied against a single or more column. You can either apply the same aggregate function across various columns or different aggregate functions across various columns.\n",
    "- Syntax : \n",
    " >- DataFrame.aggregate(self, func, axis=0, *args, ***kwargs)\n",
    " \n",
    "<img src=\"images/pandas-agg-func.png\" height=400px width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'http://bit.ly/2cLzoxH'\n",
    "# read data from url as pandas dataframe\n",
    "gapminder = pd.read_csv(data_url)\n",
    "gapminder_data = gapminder[['continent','pop']]\n",
    "gapminder_data.head()\n",
    "# gapminder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de645bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Aggregate Functions on Series\n",
    "mean  = gapminder_data['pop'].aggregate('mean')\n",
    "print(\"Mean of population : \", mean)\n",
    "\n",
    "Min  = gapminder_data['pop'].aggregate('min')\n",
    "print(\"Minimum value of population : \", Min)\n",
    "\n",
    "Max  = gapminder_data['pop'].aggregate('max')\n",
    "print(\"Maximum value of population : \", Max)\n",
    "\n",
    "Std  = gapminder_data['pop'].aggregate('std')\n",
    "print(\"Std of population : \", Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb466959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple Aggregate Functions on Dataframe\n",
    "gapminder_data['pop'].aggregate(['sum','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc654c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using multiple Aggregate Functions on Multiple columns of Dataframe\n",
    "gapminder[['pop','lifeExp']].aggregate(['sum','min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f0586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also perform above task by using below code\n",
    "gapminder.aggregate({'pop':['sum','min','max'],\n",
    "                    'lifeExp':['sum','min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8818b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()  gives overall descriptive view of our dataset\n",
    "gapminder.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dc508",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "- Pandas groupby function is used to split the DataFrame into groups based on some criteria. \n",
    "- Similar to the `SQL GROUP BY` clause pandas `DataFrame.groupby()` function is used to collect the identical data into groups and perform aggregate functions on the grouped data. Group by operation involves splitting the data, applying some functions, and finally aggregating the results.\n",
    "\n",
    "<img src=\"images/pandas-groupby-standard-dev.png.webp\" height=500px width=500px>\n",
    "<img src=\"images/groupby-example.png\" height=700px width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f42b61",
   "metadata": {},
   "source": [
    "### Syntax of Pandas DataFrame.groupby()\n",
    "\n",
    "       \n",
    "       `DataFrame.groupby(by=None, axis=0, level=None, as_index=True,     \n",
    "       sort=True, group_keys=True, squeeze=<no_default>,      \n",
    "       observed=False, dropna=True)`\n",
    "       \n",
    "       \n",
    "- `by` – List of column names to group by\n",
    "- `axis` – Default to 0. It takes 0 or ‘index’, 1 or ‘columns’\n",
    "- `level` – Used with MultiIndex.\n",
    "- `as_index` – sql style grouped otput.\n",
    "- `sort` – Default to True. Specify whether to sort after group\n",
    "- `group_keys` – add group keys or not\n",
    "- `squeeze` – depricated in new versions\n",
    "- `observed` – This only applies if any of the groupers are Categoricals.\n",
    "- `dropna` – Default to False. Use True to drop None/Nan on sory key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\",\"NA\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000,1500],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','30days','50days','40days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,None,1400,1600,0]\n",
    "          })\n",
    "df = pd.DataFrame(technologies)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37f42d",
   "metadata": {},
   "source": [
    "#### Use groupby() to compute the sum Fee and Discount of each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b11bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Courses']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarly\n",
    "df.groupby(['Courses']).aggregate('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa363720",
   "metadata": {},
   "source": [
    "#### pandas groupby() on Two or More Columns like Courses and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e69a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Courses','Duration']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b7b54",
   "metadata": {},
   "source": [
    "#### Add Index to the grouped data\n",
    "- By default `groupby()` result doesn’t include row Index, you can add the index using `DataFrame.reset_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ff9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Courses','Duration']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be5e6c",
   "metadata": {},
   "source": [
    "#### Remove sorting on grouped results by using `sort` parameter of df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ff937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2=df.groupby(by=['Courses'], sort=False).sum()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7b15e",
   "metadata": {},
   "source": [
    "#### Apply More Aggregations\n",
    "- You can also compute several aggregations at the same time in pandas by passing the list of agg functions to the `aggregate().`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d24cf15",
   "metadata": {},
   "source": [
    "#### Compute minimu and maximum fee of each course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a67d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Courses')['Fee'].aggregate(['min','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f17ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby multiple columns & multiple aggregations\n",
    "df.groupby('Courses').aggregate({'Duration':'count',\n",
    "                                'Fee':['min','max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7e4e53",
   "metadata": {},
   "source": [
    "## Practice Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198aa13",
   "metadata": {},
   "source": [
    "### Regiment\n",
    "- A regiment is a military unit. Its role and size varies markedly, depending on the country, service and/or a specialisation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c826893b",
   "metadata": {},
   "source": [
    "#### Step 1. Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9821aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "297c02ba",
   "metadata": {},
   "source": [
    "#### Step 2. Create the DataFrame with the following values and Assign it to a variable called regiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28246a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'], \n",
    "        'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'], \n",
    "        'name': ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze', 'Jacon', 'Ryaner', 'Sone', 'Sloan', 'Piger', 'Riani', 'Ali'], \n",
    "        'preTestScore': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "        'postTestScore': [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]}\n",
    "regiment = pd.DataFrame(raw_data)\n",
    "# regiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97a2a02",
   "metadata": {},
   "source": [
    "#### Step 3. What is the mean `preTestScore` from the regiment `Nighthawks`(Nightbird/Night owl)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment[regiment['regiment'] == 'Nighthawks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef1ea2",
   "metadata": {},
   "source": [
    "#### Step 4. Present/show general statistics by `company` of regiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby('company').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489c67d0",
   "metadata": {},
   "source": [
    "#### Step 5. What is the mean of each company's preTestScore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby('company')['preTestScore'].mean()\n",
    "\n",
    "# OR\n",
    "\n",
    "# regiment.groupby('company').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf158fa",
   "metadata": {},
   "source": [
    "#### Step 6. Presents/shows the `mean` preTestScores grouped by regiment and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f3cf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regiment.groupby(['regiment','company'])['preTestScore'].mean()\n",
    "# OR\n",
    "# regiment.groupby(['regiment', 'company']).preTestScore.mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1f5ef",
   "metadata": {},
   "source": [
    "#### Step 7. Presents/shows the `mean` preTestScores grouped by regiment and company with reset_index parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby(['regiment', 'company']).preTestScore.mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48911819",
   "metadata": {},
   "source": [
    "#### Step 8. Group the entire dataframe by regiment and company , also perform `sum` aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b04db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby(['regiment','company']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660c165",
   "metadata": {},
   "source": [
    "#### Step 9. What is the number of observations in each regiment and company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regiment.groupby(['regiment','company']).size()\n",
    "# OR \n",
    "# regiment.groupby(['regiment','company']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462657d0",
   "metadata": {},
   "source": [
    "#### Step 10. Iterate over a group and print the name and the whole data from the regiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group the dataframe by regiment, and for each regiment,\n",
    "# for name, group in regiment.groupby('regiment'):\n",
    "#     # print the name of the regiment\n",
    "#     print('Name : ',name)\n",
    "# #     print data of that regiment\n",
    "#     print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c97960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94c74048",
   "metadata": {},
   "source": [
    "## Merging, Joining and Concatenation\n",
    "Before I start with Pandas join and merge functions, let me introduce you to four different types of joins, they are inner join, left join, right join, outer join.\n",
    "<img src=\"images/Untitled.png\" height=500px width=500px align=\"right\"> \n",
    "\n",
    "- **Full outer join**: Combines results from both DataFrames. The result will have all columns from both DataFrames.\n",
    "- **Inner join**: Only those rows which are present in both DataFrame A and DataFrame B will be present in the output.\n",
    "- **Right join**: Right join uses all records from DataFrame B and matching records from DataFrame A.\n",
    "- **Left join**: Left join uses all records from DataFrame A and matching records from DataFrame B.\n",
    "\n",
    "<img src=\"images/joins.png\" height=600px width=600px align=\"left\" > \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ab9cb91",
   "metadata": {},
   "source": [
    "### Merging\n",
    "- Merging a Dataframe with one unique key.\n",
    "\n",
    "#### Syntax:\n",
    "```\n",
    "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "left_index=False, right_index=False, sort=True)\n",
    "``` \n",
    "- `left` − A DataFrame object.\n",
    "- `right` − Another DataFrame object.\n",
    "- `on` − Columns (names) to join on. Must be found in both the left and right DataFrame objects.\n",
    "- `left_on` − Columns from the left DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "- `right_on` − Columns from the right DataFrame to use as keys. Can either be column names or arrays with length equal to the length of the DataFrame.\n",
    "- `left_index` − If True, use the index (row labels) from the left DataFrame as its join key(s). In case of a DataFrame with a MultiIndex (hierarchical), the number of levels must match the number of join keys from the right DataFrame.\n",
    "- `right_index` − Same usage as left_index for the right DataFrame.\n",
    "- `how` − One of 'left', 'right', 'outer', 'inner'. Defaults to inner. Each method has been described below.\n",
    "- `sort` − Sort the result DataFrame by the join keys in lexicographical order. Defaults to True, setting to False will improve the performance substantially in many cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on='key')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d47dd",
   "metadata": {},
   "source": [
    "#### Merging Dataframe using multiple keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'])\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4a4e7",
   "metadata": {},
   "source": [
    "#### Left merge\n",
    "- In pd.merge() I pass the argument `how = left` to perform a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da43cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='left')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aba6b4",
   "metadata": {},
   "source": [
    "#### Right merge\n",
    "- In pd.merge() I pass the argument `how = right` to perform a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db97cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='right')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b7a4dc",
   "metadata": {},
   "source": [
    "#### Outer Merge\n",
    "- In pd.merge(), I pass the argument `how = outer` to perform a outer merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing employee data \n",
    "\n",
    "data1 = {'key':['K0','K1','K2','K3'],\n",
    "         'Name':['Mercy', 'Prince', 'John', 'Cena'],\n",
    "          'Address':['Canada', 'Australia', 'India', 'Japan'],\n",
    "         'Age':[27, 24, 22, 32],} \n",
    "# Define a dictionary containing employee data \n",
    "\n",
    "data2 = {'key':['K0','K1','K2','K3'],\n",
    "         'Address':['Canada', 'UK', 'India', 'USA'], \n",
    "         'Qualification':['Btech', 'B.A', 'MS', 'Phd']} \n",
    "\n",
    "# Convert the dictionary into DataFrame  \n",
    "df1 = pd.DataFrame(data1)\n",
    "# Convert the dictionary into DataFrame  \n",
    "df2 = pd.DataFrame(data2) \n",
    "\n",
    "# merging of two dataframes on basis ok `key` \n",
    "final_df = pd.merge(df1, df2, on=['key','Address'], how='outer')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34723f",
   "metadata": {},
   "source": [
    "## Join\n",
    "- Join is used to combine DataFrames having different index values.\n",
    "- `I have two different tables in Python but I’m not sure how to join them. What criteria should I consider? What are the different ways I can join these tables?`\n",
    "- Sound familiar? I have come across this question plenty of times on online discussion forums. Working with one table is fairly straightforward but things become challenging when we have data spread across two or more tables.\n",
    "- This is where the concept of Joins comes in. I cannot emphasize the number of times I have used these Joins in Pandas! They’ve come in especially handy during data science hackathons when I needed to quickly join multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa0d44",
   "metadata": {},
   "source": [
    "#### Understanding the Problem Statement\n",
    "\n",
    "- I’m sure you’re quite familiar with e-commerce sites like `Amazon` and `Flipkart` these days. We are bombarded by their advertisements when we’re visiting non-related websites – that’s the power of targeted marketing!\n",
    "- We’ll take a simple problem from a related marketing brand here. We are given two tables – one which contains data about products and the other that has customer-level information.\n",
    "- We will use these tables to understand how the different types of joins work using Pandas.\n",
    "\n",
    "#### Note: \n",
    " >- Our task is to use our joining skills and generate meaningful information from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The product dataframe contains product details like Product_ID, Product_name, Category, Price, and Seller_City. \n",
    "product=pd.DataFrame({\n",
    "    'Product_ID':[101,102,103,104,105,106,107],\n",
    "    'Product_name':['Watch','Bag','Shoes','Smartphone','Books','Oil','Laptop'],\n",
    "    'Category':['Fashion','Fashion','Fashion','Electronics','Study','Grocery','Electronics'],\n",
    "    'Price':[299.0,1350.50,2999.0,14999.0,145.0,110.0,79999.0],\n",
    "    'Seller_City':['Delhi','Mumbai','Chennai','Kolkata','Delhi','Chennai','Bengalore']\n",
    "})\n",
    "\n",
    "# The customer dataframe contains details like id, name, age, Product_ID, Purchased_Product, and City.\n",
    "customer=pd.DataFrame({\n",
    "    'id':[1,2,3,4,5,6,7,8,9],\n",
    "    'name':['Olivia','Aditya','Cory','Isabell','Dominic','Tyler','Samuel','Daniel','Jeremy'],\n",
    "    'age':[20,25,15,10,30,65,35,18,23],\n",
    "    'Product_ID':[101,0,106,0,103,104,0,0,107],\n",
    "    'Purchased_Product':['Watch','NA','Oil','NA','Shoes','Smartphone','NA','NA','Laptop'],\n",
    "    'City':['Mumbai','Delhi','Bangalore','Chennai','Chennai','Delhi','Kolkata','Delhi','Mumbai']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181585b",
   "metadata": {},
   "source": [
    "- Let’s say we want to know about all the products sold online and who purchased them. We can get this easily using an inner join.\n",
    "\n",
    "- The `merge()` function in Pandas is our friend here. By default, the merge function performs an inner join. It takes both the dataframes as arguments and the name of the column on which the join has to be performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46dc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, on='Product_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df78879",
   "metadata": {},
   "source": [
    "- Here, I have performed inner join on the product and customer dataframes on the `Product_ID` column.\n",
    "- But, what if the column names are different in the two dataframes? Then, we have to explicitly mention both the column names.\n",
    "- `left_on` and `right_on` are two arguments through which we can achieve this. `left_on` is the name of the key in the left dataframe and `right_on` in the right dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, left_on='Product_name', right_on='Purchased_Product')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba408d",
   "metadata": {},
   "source": [
    "- Let’s take things up a notch. The leadership team now wants more details about the products sold. They want to know about all the products sold by the seller to the same city i.e., seller and customer both belong to the same city.\n",
    "\n",
    "- In this case, we have to perform an inner join on both Product_ID and Seller_City of product and Product_ID and City columns of the customer dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c6d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(product, customer, left_on=['Product_ID', 'Seller_City'], right_on=['Product_ID','City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcfb3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f077b2",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "Concatenating of two or more dataframes using `.concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc0b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First DataFrame : \", df1, sep=\"\\n\")\n",
    "print(\"Second DataFrame : \", df2, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e53080e",
   "metadata": {},
   "source": [
    "The resultant DataFrame has a repeated index. If you want the new Dataframe to have its own index, set `ignore_index` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f981c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f789d00",
   "metadata": {},
   "source": [
    "#### Note: \n",
    " >- The second DataFrame is concatenating below the first one, making the resultant DataFrame have new rows. If you want the second DataFrame to be added as columns, pass the argument axis=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "# concatenation using concate function\n",
    "pd.concat(frames, axis=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c623e2",
   "metadata": {},
   "source": [
    "#### Note: \n",
    " >- Here columns of resultant dataframes are repeated to avoid this, we will append() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b67637",
   "metadata": {},
   "source": [
    "### Concatenating using `.append()` function\n",
    "- Append function concatenates along axis = 0 only. It can take multiple objects as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab0f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf409a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9119ab0b",
   "metadata": {},
   "source": [
    "## Practices \n",
    "- Import pandas library.\n",
    "- Download both datasets for this exercise from here [data1](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/data1.csv) and [data2](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/data2.csv) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a238e939",
   "metadata": {},
   "source": [
    "### Step 1 : Write a program to join the two given dataframes along rows and assign all to variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb9ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv('datasets/data1.csv')\n",
    "# data2 = pd.read_csv('datasets/data2.csv')\n",
    "# # print(\"First Data : \", data1, sep=\"\\n\")\n",
    "# # print(\"Second Data : \", data2, sep=\"\\n\")\n",
    "# print(\"Joining of two dataframes along rows wise ...\")\n",
    "# data = pd.concat([data1, data2])\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ff8e3",
   "metadata": {},
   "source": [
    "### Step 2 : Write a program to join the two given dataframes along columns and assign all to variable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41ab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv('datasets/data1.csv')\n",
    "# data2 = pd.read_csv('datasets/data2.csv')\n",
    "# # print(\"First Data : \", data1, sep=\"\\n\")\n",
    "# # print(\"Second Data : \", data2, sep=\"\\n\")\n",
    "# print(\"Joining of two dataframes along rows wise ...\")\n",
    "# data = pd.concat([data1, data2],axis=1)\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463bcd0",
   "metadata": {},
   "source": [
    "### Step 3 : Write a Pandas program to append rows to an existing DataFrame `data1` and display the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1 = pd.Series(['S6','Ehtisham Sadiq', 187], index=['student_id', 'name', 'marks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data = data1.append(s1, ignore_index=True)\n",
    "# print(\"Combined data : \", combined_data, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75560e1e",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- For `pandas.DataFrame`, both `join` and `merge` operates on columns and rename the common columns using the given suffix. In terms of row-wise alignment, `merge` provides more flexible control.\n",
    "- Different from `join` and `merge`, `concat` can operate on columns or rows, depending on the given axis, and no renaming is performed. In addition, `concat` allows defining hierachy structures by passing in `keys` and `names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8a6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3033a5a8",
   "metadata": {},
   "source": [
    "## How To Perform Data Visualization with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06db2b",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "- Data visualization is the most important step in the life cycle of data science, data analytics, or we can say in data engineering. It is more impressive, interesting and understanding when we represent our study or analysis with the help of colours and graphics. Using visualization elements like graphs, charts, maps, etc., it becomes easier for clients to understand the underlying structure, trends, patterns and relationships among variables within the dataset. Simply explaining the data summary and analysis using plain numbers becomes complicated for both, people coming from technical and non-technical backgrounds. Data visualization gives us a clear idea of what the data wants to convey to us. It makes data neutral for us to understand the data insights.\n",
    "- Data visualization involves operating a huge amount of data and converts it into meaningful and knowledgeable visuals using various tools. For visualizing data we need the best software tools to handle various types of data in structured or unstructured format from different sources such as files, web API, databases, and many more. We must choose the best visualization tool that fulfils all our requirements. The tool should support interactive plots generation, connectivity to data sources, combining data sources, automatically refresh the data, secured access to data sources, and exporting widgets. All these features allow us to make the best visuals of our data and also save time.\n",
    "#### Advantages of Data Visualization\n",
    "<img src=\"images/70513benefits.jpg\" height=600px width=600px >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54ec3a",
   "metadata": {},
   "source": [
    "### Data Visualization with Pandas:\n",
    "\n",
    "- Pandas library in python is mainly used for data analysis. It is not a data visualization library but, we can create basic plots using Pandas. Pandas is highly useful and practical if we want to create exploratory data analysis plots. We do not need to import other data visualization libraries in addition to Pandas for such tasks.\n",
    "\n",
    "- As Pandas is Python’s popular data analysis library, it provides several different functions to visualizing our data with the help of the .plot() function. There is one more advantage of using Pandas for visualization is we can serialize or create a pipeline of data analysis functions and plotting functions. It simplifies the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba7660",
   "metadata": {},
   "source": [
    "#### Creating of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a152fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#creating a DataFrame\n",
    "df = pd.DataFrame(np.random.rand(10, 4), columns=('col_1', 'col_2', 'col_3', 'col_4'))\n",
    "# Since this is a randomly generated dataframe the values will differ everytime you run this code for everyone.\n",
    "\n",
    "#displaying the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8eccdc",
   "metadata": {},
   "source": [
    "#### Line plot:\n",
    "- Line plot can be created with DataFrame.plot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2deb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4058cc",
   "metadata": {},
   "source": [
    "We have got the well-versed line plot for `df` without specifying any type of features in the `.plot()` function. We can plot graphs between two columns also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='col_1', y='col_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c3b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also generate subplots for individual columns.\n",
    "df.plot(subplots=True, figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf189fb",
   "metadata": {},
   "source": [
    "### Bar plot:\n",
    "- Now, we will create bar plots for the same dataframe. Bar plot can be created with `DataFrame.plot.bar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a97272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac952420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(stacked=True)\n",
    "# In this bar plot, the bars are stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.barh(stacked=True)\n",
    "# In this bar plot, the bars are stacked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc32ec",
   "metadata": {},
   "source": [
    "### Histogram Plot:\n",
    "Now, let’s generate a histogram for the `df`. Histogram plot can be created with `DataFrame.plot.hist()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb9e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9017ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let’s create a histogram with some other features.\n",
    "df.plot.hist(stacked=True, bins=15)\n",
    "# This is a stacked histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fa6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist(orientation=\"horizontal\", cumulative=True);\n",
    "# Here, we have added a cumulative frequency in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s create a histogram for each column individually.\n",
    "df.diff().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81a6c3",
   "metadata": {},
   "source": [
    "### Box Plot:\n",
    "Now, we will create box plot. Box plot can be created with `DataFrame.plot.box()` function or `DataFrame.boxplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65979c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method    \n",
    "df.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef443b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, generating the box plot in a horizontal form.\n",
    "df.plot.box(vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0738cf1b",
   "metadata": {},
   "source": [
    "### Area plot:\n",
    "Now, we will create a area plot. Area plot can be created with `DataFrame.plot.area()` function. By default, it is stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will create unstacked area plot.\n",
    "df.plot.area(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598cc28",
   "metadata": {},
   "source": [
    "### Scatter plot:\n",
    "Now, let’s generate a scatter plot. A Scatter plot can be created with `DataFrame.plot.scatter()` function. As we know scatter plot takes two-positional required arguments i.e. x and y to plot the graph. So, we will give the values of the  `x-axis` and `y-axis` as the name of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter('col_1', 'col_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f595ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the scatter plot between col_1 and col_2 of dataframe df. Let’s apply some styles.\n",
    "ax = df.plot.scatter('col_1', 'col_2', color='r', marker=\"*\", s=100)\n",
    "df.plot.scatter(x='col_3',y='col_4', color='b', s=100, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e532913",
   "metadata": {},
   "source": [
    "In this plot the data is spread with respect to col_2 and col_4 and the we have added some styles also like color, marker  and size of scatters. Let’s see another style of scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05c4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='col_2', y='col_4', c='col_1', s=100)\n",
    "# The c keyword is given as the name of a column to provide colours for each point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452e6ce",
   "metadata": {},
   "source": [
    "### Pie chart:\n",
    "- A Pie plot can be created with `DataFrame.plot.pie()` function or `Series.plot.pie()`. To generate a pie chart we will create series data as a pie chart is created only for one column. Let’s create a series named pie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie = pd.Series(np.random.randint(10,100,4))\n",
    "pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie.plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's apply some styles\n",
    "pie.plot.pie(autopct='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fda6177",
   "metadata": {},
   "source": [
    "### Pie Chart for DataFrame\n",
    "- A Pie chart can be created for DataFrames  also but it will generate individual pies for each column of DataFrame in the form of subplots. Let’s Create a pie chart for the dataframe also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd656a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(np.random.randint(20,100,(5,3)),columns=['col1','col2','col3'])\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.plot.pie(subplots=True, figsize=(15,15), autopct='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e230f0a",
   "metadata": {},
   "source": [
    "## Practice Exercise Part 1:\n",
    "#### Visualizing the Titanic Disaster\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/train.csv)\n",
    "- Step 3. Assign it to a variable titanic\n",
    "- Step 4. Set PassengerId as the index\n",
    "- Step 5. Create a pie chart presenting the male/female proportion\n",
    "- Step 6. Create a scatterplot with the Fare payed and the Age, differ the plot color by gender\n",
    "- Step 7. How many people survived and died , display using pie chart?\n",
    "- Step 8. Create a histogram with the Fare payed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315342a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/train.csv\"\n",
    "# titanic = pd.read_csv(url,)\n",
    "\n",
    "# # titanic = pd.read_csv(url,index_col='PassengerId')\n",
    "# # titanic.head()\n",
    "# # OR\n",
    "# titanic.set_index('PassengerId').head()\n",
    "# titanic.shape\n",
    "# males = (titanic.Sex == 'male').sum()\n",
    "# females = (titanic.Sex =='female').sum()\n",
    "# print(\"Total Males : \", males)\n",
    "# print(\"Total Females : \", females)\n",
    "# new_titanic = pd.Series([males,females])\n",
    "# new_titanic\n",
    "# new_titanic.plot.pie(labels=['Male','Female'], autopct='%.2f')\n",
    "# titanic.columns\n",
    "# # titanic.head()\n",
    "# list1 = []\n",
    "# for i in titanic.Sex:\n",
    "#     if i=='male':\n",
    "#         list1.append(1)\n",
    "#     else:\n",
    "#         list1.append(0)\n",
    "# titanic['new_Sex'] = list1\n",
    "# titanic.head()\n",
    "# titanic.plot.scatter(x='Fare',y='Age',c='new_Sex',s=10)\n",
    "# titanic.Fare.min(), titanic.Fare.max(), titanic.Fare.mean()\n",
    "# titanic.Fare.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93668be6",
   "metadata": {},
   "source": [
    "### Practice Exercise Part 2:\n",
    "- Step 1. Import the necessary libraries\n",
    "- Step 2. Import the dataset given below\n",
    "- Step 3. Assign it to a variable `df3`\n",
    "- Step 4. Create a scatter plot of `b` vs `a` by using `red` color.\n",
    "- Step 5. Create a histogram of the `a` column.\n",
    "- Step 6. Create a histogram of the `b` column and use bins=30.\n",
    "- Step 7. Create a boxplot comparing the `a` and `b` columns.\n",
    "- Step 8. Create a kde plot of the `d` column.\n",
    "- Step 9. Create a kde plot of the `d` column and Figure out how to increase the linewidth and make the linestyle dashed. (Note: You would usually not dash a kde plot line)\n",
    "- Step 10. Create an area plot of all the columns for just the rows up to 30. (hint: alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ced04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.DataFrame(np.random.rand(500,4), columns=['a','b','c','d'])\n",
    "# df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea5673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62784ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28de8d05",
   "metadata": {},
   "source": [
    "## Basic Python Pandas Exercise \n",
    "- In this exercise, we are using `Automobile Dataset` for data analysis. This Dataset has different characteristics of an auto such as body-style, wheel-base, engine-type, price, mileage, horsepower, etc.\n",
    "- Download dataset from this link [Automobile data_set](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Automobile_data.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/Automobile_data.csv\"\n",
    "automobile = pd.read_csv(url)\n",
    "automobile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad6b5e",
   "metadata": {},
   "source": [
    "### Exercise 1: From the given dataset print the first and last five rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd1b4e",
   "metadata": {},
   "source": [
    "### Exercise 2: Clean the dataset and update the CSV file(Hint: pd.read_csv(na_values={})\n",
    "Replace all column values which contain `?`, `n.a`, or `NaN.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f163efa",
   "metadata": {},
   "source": [
    "### Exercise 3: Find the most expensive car company name\n",
    "Print most expensive car’s company name and price.     \n",
    "**Expected Output:**\n",
    "![](images/pandas_printing_most_costly_car_name.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "a = automobile.groupby(['company'])['price'].max()\n",
    "a.sort_values(ascending=False).reset_index().head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6419cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "b = automobile[['company','price']][automobile['price'] == automobile['price'].max()]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba999a8",
   "metadata": {},
   "source": [
    "### Exercise 4: Print All Toyota Cars details\n",
    "**Expected Output**\n",
    "![](images/pandas_printing_all_toyota_car_data.png)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15550206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First Method\n",
    "# automobile[automobile['company'] == 'toyota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a631ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second Method\n",
    "# group = automobile.groupby('company')\n",
    "# group.get_group('toyota')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c14f2da",
   "metadata": {},
   "source": [
    "### Exercise 5: Count total cars per company\n",
    "**Expected Output**\n",
    "![](images/pandas_count_total_cars_per_company.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb28b24",
   "metadata": {},
   "source": [
    "### Exercise 6: Find each company’s Higesht price car\n",
    "**Expected Outcome:**\n",
    "![](images/pandas_printing_each_companys_higesht_price_car.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "# automobile.groupby(['company'])['price'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "# automobile.groupby('company')[['company','price']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3b36d7",
   "metadata": {},
   "source": [
    "### Exercise 7: Find the average mileage of each car making company\n",
    "**Expected Output:**\n",
    "![](images/pandas_printing_average_mileage_of_each_car_making_company.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467aadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Method\n",
    "# automobile.groupby('company')['company','average-mileage'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df38afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Method\n",
    "# result = automobile.groupby('company')\n",
    "# result['company','average-mileage'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd090654",
   "metadata": {},
   "source": [
    "### Exercise 8: Sort all cars by Price column\n",
    "**Expected Output:**\n",
    "![](images/pandas_sort_all_cars_by_price_column.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b178e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automobile.sort_values(by=['price'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc19be4",
   "metadata": {},
   "source": [
    "### Exercise 9: Concatenate two data frames using the following conditions\n",
    "Create two data frames using the following two dictionaries.\n",
    "![](images/pandas_concatenate_two_data_frames_and_create_key_for_each_data_frame.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ea9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GermanCars = {'Company': ['Ford', 'Mercedes', 'BMV', 'Audi'], 'Price': [23845, 171995, 135925 , 71400]}\n",
    "japaneseCars = {'Company': ['Toyota', 'Honda', 'Nissan', 'Mitsubishi '], 'Price': [29995, 23600, 61500 , 58900]}\n",
    "# German = pd.DataFrame(GermanCars)\n",
    "# Japan = pd.DataFrame(japaneseCars)\n",
    "# df = pd.concat([German,Japan], keys=['German','Japan'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e8f3f",
   "metadata": {},
   "source": [
    "### Exercise 10: Merge two data frames using the following condition\n",
    "Create two data frames using the following two Dicts, Merge two data frames, and append the second data frame as a new column to the first data frame.\n",
    "![](images/merge_two_data_frames_and_append_new_data_frame_as_new-column.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed369803",
   "metadata": {},
   "outputs": [],
   "source": [
    "Car_Price = {'Company': ['Toyota', 'Honda', 'BMV', 'Audi'], 'Price': [23845, 17995, 135925 , 71400]}\n",
    "car_Horsepower = {'Company': ['Toyota', 'Honda', 'BMV', 'Audi'], 'horsepower': [141, 80, 182 , 160]}\n",
    "price = pd.DataFrame.from_dict(Car_Price)\n",
    "horsepower = pd.DataFrame.from_dict(car_Horsepower)\n",
    "pd.merge(price,horsepower,on='Company')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ba3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fd3124d",
   "metadata": {},
   "source": [
    "## Pandas Data Visualization Exercise\n",
    "This is just a quick exercise for you to review the various plots we showed earlier. Use **datasets/practice.csv** to replicate the following plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ab777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfb16d8",
   "metadata": {},
   "source": [
    "### Q-01: Import your dataset and also display first five rows of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8e99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/practice')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e0fb6",
   "metadata": {},
   "source": [
    "**Q-02: Create this scatter plot of `b` vs `a`. Note the color and size of the points. Also note the figure size. See if you can figure out how to stretch it in a similar fashion. Remeber back to your matplotlib lecture...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e30a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdee4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c3f111",
   "metadata": {},
   "source": [
    "**Create a histogram of the 'a' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1f049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7afe968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79e90fc",
   "metadata": {},
   "source": [
    "**These plots are okay, but they don't look very polished. Use style sheets to set the style to 'plt.style.use('ggplot') and redo the histogram from above. Also figure out how to add more `bins` and `alpha` to it.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e67e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89918ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c04396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e11537c7",
   "metadata": {},
   "source": [
    "**Create a boxplot comparing the `a` and `b` columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f25485",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['a','b']].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e016065a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3563a20",
   "metadata": {},
   "source": [
    "**Create a kde plot of the `d` column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d18c06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9157fba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53452bb8",
   "metadata": {},
   "source": [
    "**Figure out how to increase the linewidth and make the linestyle dashed. (Note: You would usually not dash a kde plot line)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e1169f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50a7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "195e90c3",
   "metadata": {},
   "source": [
    "**Create an area plot of all the columns for just the rows up to `30.` (hint: use `.ix`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68358a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f5e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2577f2a",
   "metadata": {},
   "source": [
    "# Pandas - Assignment No 01\n",
    "- Click here to solve [Pandas - Assignment no 01](https://www.kaggle.com/code/ehtishamsadiq/pandas-assignment-no-01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5084fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
