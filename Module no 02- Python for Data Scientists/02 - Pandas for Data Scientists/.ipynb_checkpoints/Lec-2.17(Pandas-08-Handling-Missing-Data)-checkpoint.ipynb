{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a87b5ef",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<h1 align=\"center\">Introduction to Data Analyst and Data Science for beginners</h1>\n",
    "<h1 align=\"center\">Lecture no 2.17(Pandas-08)</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Ehtisham Sadiq</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f82705",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/pandas-apps.png\"  >\n",
    "\n",
    "## _Handling Missing Data.ipynb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32465884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae0f822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12db95e1",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "\n",
    "1. Have an insight about the Dataset\n",
    "2. Identify the Columns having Null/Missing values using `df.isna()` method\n",
    "3. Handle/Impute the Null/Missing Values under the `math` Column using `df.loc[mask,col]=value`\n",
    "4. Handle/Impute the Null/Missing Values under the `group` Column using `df.loc[mask,col]=value`\n",
    "5. Handle Missing values under a Numeric/Categorical Column using `fillna()`\n",
    "6. Handle Repeating Values (for same information) under the `session` Column\n",
    "7. Create a new Column by Modifying an Existing Column\n",
    "8. Delete Rows Having NaN values using `df.dropna()` method\n",
    "9. Convert Categorical Variables into Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d2bba7a",
   "metadata": {},
   "source": [
    "## 1. Have an Insight about the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/group-marks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ed7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d90a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a182fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8653443c",
   "metadata": {},
   "source": [
    "- Whenever the **`pd.read.csv()`** method detects a missing value (nothing between two commas in a csv file or an empty cell in Excel) it flags it with NaN. There can be many reasons for these NaN values, one can be that the data is gathered via google form from people and this field might be optional and skipped.\n",
    "- There can also be a scenario that a user has entered some text under a numeric field about which he/she do not have any information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c0e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2505bd5",
   "metadata": {},
   "source": [
    "## 2. Identify the Columns having Null/Missing values\n",
    "- The **`df.isna()`** method isrecommended to use than `df.isnull()`, which return a boolean same-sized object that indicates whether an element is NA value or not. Missing values get mapped to True. Everything else gets mapped to False values. Remember, characters such as empty strings ``''`` or `numpy.inf` are not considered NA values.\n",
    "- The **`df.notna()`** method is recommended to use than `df.notnull()` methods return a boolean same-sized object that indicates whether an element is NA value or not. Non-missing values get mapped to True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ed31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af437830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use sum() on this dataframe object of Boolean values (True is mapped to 1)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can use sum() on this dataframe object of Boolean values (True is is mapped to 1)\n",
    "df.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e02d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14dd039f",
   "metadata": {},
   "source": [
    "## 3. Handle/Impute the Null/Missing Values under the `math` Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190177e8",
   "metadata": {},
   "source": [
    "### a. Identify the Rows under the `math` Column having Null/Missing values\n",
    "- The `df.isna()` method works equally good on Series objects as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e30622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.math.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0853c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.math.isna()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[mask]\n",
    "# df.loc[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fa5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return only those rows of dataframe having null values under the math column\n",
    "df[mask]         # df[df.math.isna()]\n",
    "df.loc[mask, :]  # df.loc[df.math.isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c7ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "430a2bed",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `math` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values under the `math` column\n",
    "- Suppose, we want to put the average values at the place of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean of math column\n",
    "# df.math.mean()\n",
    "# df.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940b60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae5eca68",
   "metadata": {},
   "source": [
    "> By seeing the error, it appears that the `math` column do not have the `int64` or `float64` type. Let us check this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fb2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e345df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the `df.info()` method to display the count of Non-Null columns, their datatypes, their names \n",
    "# and memory usage of that dataframe.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6affc95",
   "metadata": {},
   "source": [
    "- **What can be the reason for this?**\n",
    "- Let us check out the values under this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739483d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cf742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can replace all such values using the `replace()` method\n",
    "import numpy as np\n",
    "df.replace('No Idea', np.nan).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26efcede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfede51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939e53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the marks of Saadia in math are changed from string `No Idea` to `NaN`\n",
    "# Since this seems working fine let us make inplace=True to make these changes in the original dataframe\n",
    "df.replace('No Idea', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c17ec0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ee44f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8008ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is still Object, which is natural, however, we can change the datatype to `df.astype()` method\n",
    "df['math'] = df['math'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16b303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf25352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us check the data type of math column\n",
    "df['math'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb34ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us compute the average of math marks again \n",
    "df.math.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.math.isna()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df22e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only those records under math column having Null values\n",
    "df.loc[mask, 'math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us replace these values with mean value of the math column\n",
    "df.loc[(df.math.isna()),'math'] = df.math.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8abade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e3406a",
   "metadata": {},
   "source": [
    "### Handle the missing values under `English` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.english.dtype\n",
    "# fetch rows which contain null or missing values\n",
    "df.loc[df.english.isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb56049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean of data/column\n",
    "df.loc[df.english.isna(),'english'] = df.english.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d1bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b359f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ac58bc",
   "metadata": {},
   "source": [
    "## 4. Handle/Impute the Null/Missing Values under the `group` Column\n",
    "- The `group` column contains categorical values, i.e., a value that can take on one of a limited, and usually fixed, number of possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebb9ae",
   "metadata": {},
   "source": [
    "### a. Identify the Rows under the `group` Column having Null/Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf14128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e93928",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.group.isna()\n",
    "mask.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7438404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask]          # df[df.group.isna()]\n",
    "df.loc[mask, :]   # df.loc[df.group.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638dd05",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `group` Column\n",
    "- After detecting the NaN values, the next question is, what value we should write in the cells where we have Null/Missing values\n",
    "- Since this is a categorical column having datatype object (group A, group B, group C, ...), so let us replace it with th value inside the column having the maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts() function which return a Series containing counts of unique values (in descending order)\n",
    "# with the most frequently-occurring element at first. It excludes NA values by default.\n",
    "df.group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c21ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of doing is use the mode() function on the column\n",
    "df.group.mode() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acc161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f362b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c578a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List only those records under group column having Null values\n",
    "mask = df.group.isna()\n",
    "df.loc[mask, 'group']     # df.loc[(df.group.isna()), 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2758fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us replace these values with maximum occurring value in the `group` column\n",
    "df.loc[(df.group.isna()),'group'] = 'group C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69298cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65193323",
   "metadata": {},
   "source": [
    ">Note that in the original dataframe Arifa group information was missing, and now it is `group C` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c954256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406a2755",
   "metadata": {},
   "source": [
    "## 5. Handle Missing values under a Numeric/Categorical Column using `fillna()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b16b8",
   "metadata": {},
   "source": [
    "### a. Replace the Null/Missing Values under the math Column using `fillna()`\n",
    "- This is more recommended way of filling in the Null values within columns of your dataset rather than the use of the `loc` method.\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "- The only required argument is either the `value`, with which we want to replace the missing values OR the `method` to be used to replace the missing values\n",
    "- Returns object with missing values filled or None if ``inplace=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe077e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values under math column\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2206c",
   "metadata": {},
   "source": [
    ">- Before proceeding, let us this time handle the string value `No Idea` under the math column while reading the csv file, instead of doing afterwards in the dataframe using the `replace()` method as we have done above.\n",
    ">- For this we will use the `na_values` argument to the `pd.read_csv()` method, to which you can pass a single value or a list of values to be replaced with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.math.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00977e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8007a41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8541f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time instead of loc, use fillna() method with just two arguments\n",
    "# inplace=True parameter ensure that this happens in the original dataframe\n",
    "\n",
    "df.math.fillna(value=df.math.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60298853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeac35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6f5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926ec32f",
   "metadata": {},
   "source": [
    "### b. Replace the Null/Missing Values under the `group` Column using `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad051b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again instead of loc,let us use fillna() method with just two arguments\n",
    "\n",
    "df.group.fillna('group C', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70222f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803f22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d032cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us fill the math, english and scholarship columns as well again\n",
    "df.math.fillna(df.math.mean(), inplace=True)\n",
    "df.english.fillna(df.english.mean(), inplace=True)\n",
    "df.scholarship.fillna(df.scholarship.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c214fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729361a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e88d9dc",
   "metadata": {},
   "source": [
    "### c. Replace the Null/Missing Values under the` math` and `group` Column using `ffill` and `bfill` Arguments\n",
    "- In above examples, we have used the mean value in case of numeric column and mode value in case of a categorical column as the filling value to the `fillna()` method\n",
    "```\n",
    "object.fillna(value, method, inplace=True)\n",
    "```\n",
    "\n",
    "- We can pass `ffill` or `bfill` as method argument to the `ffillna()` method. This will replace the null values with other values from the DataFrame\n",
    "- `ffill` (Forward fill): It fills the NaN value with the previous value\n",
    "- `bfill` (Back fill): It fills the NaN value with the Next/Upcoming value\n",
    "\n",
    "<img align=\"right\" width=\"490\" height=\"100\"  src=\"images/bfill.PNG\"  >\n",
    "<img align=\"left\" width=\"490\" height=\"100\"  src=\"images/ffill.PNG\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ec42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us read the dataset again with NA values\n",
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv', na_values='No Idea')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2edccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967c27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0748ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill or ffill attribute\n",
    "# If have NaN value, just carry forward the previous value\n",
    "# using ffill attribute, you can fill the NaN value with the previous value in that column\n",
    "df.fillna(method = 'ffill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0558882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49023d8",
   "metadata": {},
   "source": [
    ">Is it working fine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8cd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b085425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method = 'bfill', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca48c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the result\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c6345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "849f595d",
   "metadata": {},
   "source": [
    "## 6. Handle Repeating Values (for same information) under the `session` Column\n",
    "- If you observe the values under the `session` column, you can observe that it is a categorical column containing six different categories (as values).\n",
    "    - Notice that the categories `MORNING` and `MOR` are same\n",
    "    - Similarly, `AFTERNOON` and `AFT` are same\n",
    "    - Similarly, `EVENING` and `EVE` are same\n",
    "- This happens when you have collected data from different sources, where same information is written in different ways\n",
    "- So the `session` column has six different categories (as values) but should have only three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39378b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv' )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6266ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let use check out the counts of unique values inside the session Column\n",
    "df.session.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebb2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e20639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e160c362",
   "metadata": {},
   "source": [
    "###  Handle  the Repeating Values under the session Column using `map()`\n",
    "- To keep the data clean we will map all these values to only three categories to `MOR` , `AFT` and `EVE` using the map() function.\n",
    "```\n",
    "df.map(mapping, na_action=None)\n",
    "```\n",
    "- The `map()` method is used for substituting each value in a Series with another value, that may be derived from a `dict`. The `map()` method returns a series after performing the mapping\n",
    "- You can give `ignore` as second argument which will propagate NaN values, without passing them to the mapping correspondence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do this, let us create a new mapping (dictionary) \n",
    "dict1 = {\n",
    "    'MORNING' : 'MOR',\n",
    "    'MOR' : 'MOR',\n",
    "    'AFTERNOON' : 'AFT',\n",
    "    'AFT': 'AFT',\n",
    "    'EVENING' : 'EVE',\n",
    "    'EVE': 'EVE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It returns a series with the same index as caller, the original series remains unchanged. \n",
    "# So we have assigned the resulting series to `df.session` series\n",
    "df.session.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c5c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.session = df.session.map(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of new categories in the column session\n",
    "# Observe we have managed to properly manage the values inside the session column\n",
    "df.session.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us verify the result\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe79ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07d53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d90de5",
   "metadata": {},
   "source": [
    "## 7. Create a new Column by Modifying an Existing Column\n",
    "- We have a column scholarship in the dataset, which is in Pak Rupees\n",
    "- Suppose you want to have a new column which should represent the scholarship in US Dollars\n",
    "- For that we need to add a new column by dividing each value of scholarship with 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3133b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv' )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.scholarship.apply(lambda x: x/170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Scholarship_in_$'] = df.scholarship.apply(lambda x : x/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb8118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88eea76d",
   "metadata": {},
   "source": [
    "## 8. Delete Rows Having NaN values using `df.dropna()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef83e54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc99975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac322b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use dropna() method to drop all the rows, it it has any na value\n",
    "df1 = df.dropna()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e91e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5d7f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Arguments to dropna()\n",
    "df2 = df.dropna(axis=0, how='any')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5776a24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set how='all` it means drop a row only if all of its values are NA\n",
    "df2 = df.dropna(axis=0, how='all')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cc0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of subset argument and pass it a list of columns based on whose values you want to drop a row\n",
    "df2 = df.dropna(axis=0, how='any', subset=['math'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea1093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c409a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use of subset argument\n",
    "df2 = df.dropna(axis=0, how='any', subset=['session'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf8668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having `how=all` and `subset=listofcolumnnames`, then it will \n",
    "# drop a row only if both the columns have a NA value in that row\n",
    "df2 = df.dropna(axis=0, how='any', subset=['math', 'session'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedf621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b79a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13d514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set the axis=1 and how=all, it means drop a column if all the  values under it is na\n",
    "df2 = df.dropna(axis=1, how='all')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9262c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we set the axis=1 and how=any, it means drop a column if any value under it is na\n",
    "df2 = df.dropna(axis=1, how='any')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24231c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d527fdbe",
   "metadata": {},
   "source": [
    "## 9. Convert Categorical Variables into Numerical\n",
    "- Most of the machine learning algorithms do not take categorical variables so we need to convert them into numerical ones. \n",
    "- We can do this using Pandas function `pd.get_dummies()`, which will create a binary column for each of the categories. \n",
    "```\n",
    "pd.get_dummies(data, drop_first=False)\n",
    "```\n",
    "- Where, the only required argument is `data` which can be a dataframe or a series\n",
    "- The parameter drop_first : bool, default False Whether to get k-1 dummies out of k categorical levels by removing the first level.\n",
    "\n",
    "**Note:** Making a dummy variable will take all the `K` distinct values in one coumn and make `K` columns out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c50a3",
   "metadata": {},
   "source": [
    "### a. Convert all categorical variables into dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e83961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/group-marks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently we have 10 columns in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d3c674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view the datafreame, keep a note on the number of columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4ca5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The Number of columns has gone to 142 now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94e433",
   "metadata": {},
   "source": [
    "- So we have 112 columns\n",
    "- Even though one-hot encoding is a good way to convert your categorical columns to numerical columns\n",
    "- But it adds a lot of dimensionality to your data, i.e., increase the number of columns\n",
    "- It also become difficult to deal with that much number of columns\n",
    "- This is a trade-off, which is handled by technique called dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8064be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf725cc0",
   "metadata": {},
   "source": [
    "### b. Perform One-Hot Encoding for Categorical Column `gender` Only\n",
    "- In our dataframe, the gender column is a categorical column having two values 'male' and 'female'\n",
    "- It will create a dummy binary columns.  \n",
    "- This is also known as `One Hot Encoding`. You will learn more encoding techniques in the data pre-processing module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f41e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('datasets/group-marks.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb554eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058940b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert only gender variable into dummy/indicator variables\n",
    "df2 = pd.get_dummies(df1[['gender']])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a111866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we donot need two separate columns, so simply use the `drop_first` argument of get_dummies to handle this\n",
    "df2 = pd.get_dummies(df1[['gender']], drop_first=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7a40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will talk about join in the next session in detail.\n",
    "df3 = df1.join(df2['gender_male'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7f244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60d03092",
   "metadata": {},
   "source": [
    "## Check Your Concepts:\n",
    "- What is Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5e112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d15f032a",
   "metadata": {},
   "source": [
    "## Practice Questions\n",
    "For the practice questions, we will use following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a62e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ord_no': [70001,\n",
       "  nan,\n",
       "  70002,\n",
       "  70004,\n",
       "  nan,\n",
       "  70005,\n",
       "  nan,\n",
       "  70010,\n",
       "  70003,\n",
       "  70012,\n",
       "  nan,\n",
       "  70013],\n",
       " 'purch_amt': [150.5,\n",
       "  270.65,\n",
       "  65.26,\n",
       "  110.5,\n",
       "  948.5,\n",
       "  2400.6,\n",
       "  5760,\n",
       "  1983.43,\n",
       "  2480.4,\n",
       "  250.45,\n",
       "  75.29,\n",
       "  3045.6],\n",
       " 'ord_date': ['2012-10-05',\n",
       "  '2012-09-10',\n",
       "  nan,\n",
       "  '2012-08-17',\n",
       "  '2012-09-10',\n",
       "  '2012-07-27',\n",
       "  '2012-09-10',\n",
       "  '2012-10-10',\n",
       "  '2012-10-10',\n",
       "  '2012-06-27',\n",
       "  '2012-08-17',\n",
       "  '2012-04-25'],\n",
       " 'customer_id': [3002,\n",
       "  3001,\n",
       "  3001,\n",
       "  3003,\n",
       "  3002,\n",
       "  3001,\n",
       "  3001,\n",
       "  3004,\n",
       "  3003,\n",
       "  3002,\n",
       "  3001,\n",
       "  3001],\n",
       " 'salesman_id': [5002,\n",
       "  5003,\n",
       "  5001,\n",
       "  nan,\n",
       "  5002,\n",
       "  5001,\n",
       "  5001,\n",
       "  nan,\n",
       "  5003,\n",
       "  5002,\n",
       "  5003,\n",
       "  nan]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dict1 ={\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]\n",
    "}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d7eaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001.0</td>\n",
       "      <td>150.50</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.50</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>3045.60</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
       "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
       "1       NaN     270.65  2012-09-10         3001       5003.0\n",
       "2   70002.0      65.26         NaN         3001       5001.0\n",
       "3   70004.0     110.50  2012-08-17         3003          NaN\n",
       "4       NaN     948.50  2012-09-10         3002       5002.0\n",
       "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
       "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
       "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
       "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
       "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
       "10      NaN      75.29  2012-08-17         3001       5003.0\n",
       "11  70013.0    3045.60  2012-04-25         3001          NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10763c",
   "metadata": {},
   "source": [
    "### Write a Pandas program to detect missing values of a given DataFrame.(Hint : df.isna() ordf.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9552d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_no         4\n",
       "purch_amt      0\n",
       "ord_date       1\n",
       "customer_id    0\n",
       "salesman_id    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(dict1)\n",
    "# df.isnull().sum()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a39a521",
   "metadata": {},
   "source": [
    "### Write a Pandas program to identify the column(s) of a given DataFrame which have at least one missing value.(Hint : df.isna().sum or df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc259dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001.0</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no    ord_date  salesman_id\n",
       "0   70001.0  2012-10-05       5002.0\n",
       "1       NaN  2012-09-10       5003.0\n",
       "2   70002.0         NaN       5001.0\n",
       "3   70004.0  2012-08-17          NaN\n",
       "4       NaN  2012-09-10       5002.0\n",
       "5   70005.0  2012-07-27       5001.0\n",
       "6       NaN  2012-09-10       5001.0\n",
       "7   70010.0  2012-10-10          NaN\n",
       "8   70003.0  2012-10-10       5003.0\n",
       "9   70012.0  2012-06-27       5002.0\n",
       "10      NaN  2012-08-17       5003.0\n",
       "11  70013.0  2012-04-25          NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask = df.isnull().any()\n",
    "# mask\n",
    "\n",
    "mask = df.isna().any()\n",
    "df.loc[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdbfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466c09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8937a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c7683fc",
   "metadata": {},
   "source": [
    "### Write a Pandas program to count the number of missing values in each column of a given DataFrame.(Hint: df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e888086a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_no         33.333333\n",
       "purch_amt       0.000000\n",
       "ord_date        8.333333\n",
       "customer_id     0.000000\n",
       "salesman_id    25.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((df.isna().sum())/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1293ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33b1dff1",
   "metadata": {},
   "source": [
    "### Write a Pandas program to find and replace the missing values in a given DataFrame which do not have any valuable information.(Hint : pd.read_csv(na_values) or df.replace())\n",
    "For this question , use following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1b5d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ord_no': [70001,\n",
       "  nan,\n",
       "  70002,\n",
       "  70004,\n",
       "  nan,\n",
       "  70005,\n",
       "  '--',\n",
       "  70010,\n",
       "  70003,\n",
       "  70012,\n",
       "  nan,\n",
       "  70013],\n",
       " 'purch_amt': [150.5,\n",
       "  270.65,\n",
       "  65.26,\n",
       "  110.5,\n",
       "  948.5,\n",
       "  2400.6,\n",
       "  5760,\n",
       "  '?',\n",
       "  12.43,\n",
       "  2480.4,\n",
       "  250.45,\n",
       "  3045.6],\n",
       " 'ord_date': ['?',\n",
       "  '2012-09-10',\n",
       "  nan,\n",
       "  '2012-08-17',\n",
       "  '2012-09-10',\n",
       "  '2012-07-27',\n",
       "  '2012-09-10',\n",
       "  '2012-10-10',\n",
       "  '2012-10-10',\n",
       "  '2012-06-27',\n",
       "  '2012-08-17',\n",
       "  '2012-04-25'],\n",
       " 'customer_id': [3002,\n",
       "  3001,\n",
       "  3001,\n",
       "  3003,\n",
       "  3002,\n",
       "  3001,\n",
       "  3001,\n",
       "  3004,\n",
       "  '--',\n",
       "  3002,\n",
       "  3001,\n",
       "  3001],\n",
       " 'salesman_id': [5002,\n",
       "  5003,\n",
       "  '?',\n",
       "  5001,\n",
       "  nan,\n",
       "  5002,\n",
       "  5001,\n",
       "  '?',\n",
       "  5003,\n",
       "  5002,\n",
       "  5003,\n",
       "  '--']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,\"--\",70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,\"?\",12.43,2480.4,250.45, 3045.6],\n",
    "'ord_date': ['?','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,\"--\",3002,3001,3001],\n",
    "'salesman_id':[5002,5003,\"?\",5001,np.nan,5002,5001,\"?\",5003,5002,5003,\"--\"]}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3556202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001</td>\n",
       "      <td>150.5</td>\n",
       "      <td>?</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004</td>\n",
       "      <td>110.5</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.5</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005</td>\n",
       "      <td>2400.6</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--</td>\n",
       "      <td>5760</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010</td>\n",
       "      <td>?</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003</td>\n",
       "      <td>12.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>--</td>\n",
       "      <td>5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012</td>\n",
       "      <td>2480.4</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013</td>\n",
       "      <td>3045.6</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ord_no purch_amt    ord_date customer_id salesman_id\n",
       "0   70001     150.5           ?        3002        5002\n",
       "1     NaN    270.65  2012-09-10        3001        5003\n",
       "2   70002     65.26         NaN        3001           ?\n",
       "3   70004     110.5  2012-08-17        3003        5001\n",
       "4     NaN     948.5  2012-09-10        3002         NaN\n",
       "5   70005    2400.6  2012-07-27        3001        5002\n",
       "6      --      5760  2012-09-10        3001        5001\n",
       "7   70010         ?  2012-10-10        3004           ?\n",
       "8   70003     12.43  2012-10-10          --        5003\n",
       "9   70012    2480.4  2012-06-27        3002        5002\n",
       "10    NaN    250.45  2012-08-17        3001        5003\n",
       "11  70013    3045.6  2012-04-25        3001          --"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2793ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'?':np.nan, '--':np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44c4e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.salesman_id.fillna(df.salesman_id.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf6a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b519aa12",
   "metadata": {},
   "source": [
    "### Write a Pandas program to drop the rows where at least one element is missing in a given DataFrame.(Hint : df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0a20dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001.0</td>\n",
       "      <td>150.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.50</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>12.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>3045.60</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
       "0   70001.0     150.50         NaN       3002.0       5002.0\n",
       "1       NaN     270.65  2012-09-10       3001.0       5003.0\n",
       "2   70002.0      65.26         NaN       3001.0          NaN\n",
       "3   70004.0     110.50  2012-08-17       3003.0       5001.0\n",
       "4       NaN     948.50  2012-09-10       3002.0          NaN\n",
       "5   70005.0    2400.60  2012-07-27       3001.0       5002.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0       5001.0\n",
       "7   70010.0        NaN  2012-10-10       3004.0          NaN\n",
       "8   70003.0      12.43  2012-10-10          NaN       5003.0\n",
       "9   70012.0    2480.40  2012-06-27       3002.0       5002.0\n",
       "10      NaN     250.45  2012-08-17       3001.0       5003.0\n",
       "11  70013.0    3045.60  2012-04-25       3001.0          NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6de20f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003.0</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.6</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>2480.4</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
       "3  70004.0      110.5  2012-08-17       3003.0       5001.0\n",
       "5  70005.0     2400.6  2012-07-27       3001.0       5002.0\n",
       "9  70012.0     2480.4  2012-06-27       3002.0       5002.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66274cd9",
   "metadata": {},
   "source": [
    "### Write a Pandas program to drop the columns where at least one element is missing in a given DataFrame.(Hint : df.dropna())\n",
    "For this question , ue following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ad88fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>salesman_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70001.0</td>\n",
       "      <td>150.50</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.50</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001</td>\n",
       "      <td>5001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002</td>\n",
       "      <td>5002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001</td>\n",
       "      <td>5003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>3045.60</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
       "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
       "1       NaN     270.65  2012-09-10         3001       5003.0\n",
       "2   70002.0      65.26         NaN         3001       5001.0\n",
       "3   70004.0     110.50  2012-08-17         3003          NaN\n",
       "4       NaN     948.50  2012-09-10         3002       5002.0\n",
       "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
       "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
       "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
       "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
       "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
       "10      NaN      75.29  2012-08-17         3001       5003.0\n",
       "11  70013.0    3045.60  2012-04-25         3001          NaN"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bc9f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.50</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270.65</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.26</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.50</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>948.50</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2400.60</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5760.00</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1983.43</td>\n",
       "      <td>3004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2480.40</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.45</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.29</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3045.60</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    purch_amt  customer_id\n",
       "0      150.50         3002\n",
       "1      270.65         3001\n",
       "2       65.26         3001\n",
       "3      110.50         3003\n",
       "4      948.50         3002\n",
       "5     2400.60         3001\n",
       "6     5760.00         3001\n",
       "7     1983.43         3004\n",
       "8     2480.40         3003\n",
       "9      250.45         3002\n",
       "10      75.29         3001\n",
       "11    3045.60         3001"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method1\n",
    "df.dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2c7c1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.50</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270.65</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.26</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.50</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>948.50</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2400.60</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5760.00</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1983.43</td>\n",
       "      <td>3004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2480.40</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.45</td>\n",
       "      <td>3002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.29</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3045.60</td>\n",
       "      <td>3001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    purch_amt  customer_id\n",
       "0      150.50         3002\n",
       "1      270.65         3001\n",
       "2       65.26         3001\n",
       "3      110.50         3003\n",
       "4      948.50         3002\n",
       "5     2400.60         3001\n",
       "6     5760.00         3001\n",
       "7     1983.43         3004\n",
       "8     2480.40         3003\n",
       "9      250.45         3002\n",
       "10      75.29         3001\n",
       "11    3045.60         3001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isna().sum() == 0\n",
    "# df.isna().sum()\n",
    "mask = df.isna().sum() == 0\n",
    "df.loc[:,mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45469d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd3d0f6",
   "metadata": {},
   "source": [
    "### Write a Pandas program to drop the rows where all elements are missing in a given DataFrame.(Hint : df.drop())\n",
    "For this question, we will use following dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fdf5c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.50</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>3045.60</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id\n",
       "0       NaN        NaN         NaN          NaN\n",
       "1       NaN     270.65  2012-09-10       3001.0\n",
       "2   70002.0      65.26         NaN       3001.0\n",
       "3   70004.0     110.50  2012-08-17       3003.0\n",
       "4       NaN     948.50  2012-09-10       3002.0\n",
       "5   70005.0    2400.60  2012-07-27       3001.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0\n",
       "7   70010.0    1983.43  2012-10-10       3004.0\n",
       "8   70003.0    2480.40  2012-10-10       3003.0\n",
       "9   70012.0     250.45  2012-06-27       3002.0\n",
       "10      NaN      75.29  2012-08-17       3001.0\n",
       "11  70013.0    3045.60  2012-04-25       3001.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {\n",
    "'ord_no':[np.nan,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[np.nan,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': [np.nan,'2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[np.nan,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001]}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "424c8987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(labels=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc188853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59aea1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70004.0</td>\n",
       "      <td>110.50</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70013.0</td>\n",
       "      <td>3045.60</td>\n",
       "      <td>2012-04-25</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id\n",
       "0       NaN        NaN         NaN          NaN\n",
       "1       NaN     270.65  2012-09-10       3001.0\n",
       "2   70002.0      65.26         NaN       3001.0\n",
       "3   70004.0     110.50  2012-08-17       3003.0\n",
       "4       NaN     948.50  2012-09-10       3002.0\n",
       "5   70005.0    2400.60  2012-07-27       3001.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0\n",
       "7   70010.0    1983.43  2012-10-10       3004.0\n",
       "8   70003.0    2480.40  2012-10-10       3003.0\n",
       "9   70012.0     250.45  2012-06-27       3002.0\n",
       "10      NaN      75.29  2012-08-17       3001.0\n",
       "11  70013.0    3045.60  2012-04-25       3001.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.loc[df.isna().index]\n",
    "df.loc[:,df.isna().sum().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcbedd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706087a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2435f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b21dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d93624",
   "metadata": {},
   "source": [
    "### Write a Pandas program to keep the rows with at least 2 NaN values in a given DataFrame.(Hint: df.dropna(thresh=))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afa5c706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id\n",
       "0       NaN        NaN         NaN          NaN\n",
       "1       NaN     270.65  2012-09-10       3001.0\n",
       "2   70002.0      65.26         NaN       3001.0\n",
       "3       NaN        NaN         NaN          NaN\n",
       "4       NaN     948.50  2012-09-10       3002.0\n",
       "5   70005.0    2400.60  2012-07-27       3001.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0\n",
       "7   70010.0    1983.43  2012-10-10       3004.0\n",
       "8   70003.0    2480.40  2012-10-10       3003.0\n",
       "9   70012.0     250.45  2012-06-27       3002.0\n",
       "10      NaN      75.29  2012-08-17       3001.0\n",
       "11      NaN        NaN         NaN          NaN"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {\n",
    "'ord_no':[np.nan,np.nan,70002,np.nan,np.nan,70005,np.nan,70010,70003,70012,np.nan,np.nan],\n",
    "'purch_amt':[np.nan,270.65,65.26,np.nan,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,np.nan],\n",
    "'ord_date': [np.nan,'2012-09-10',np.nan,np.nan,'2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17',np.nan],\n",
    "'customer_id':[np.nan,3001,3001,np.nan,3002,3001,3001,3004,3003,3002,3001,np.nan]}\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f668daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054c293",
   "metadata": {},
   "source": [
    "### Write a Pandas program to drop those rows from a given DataFrame in which specific columns have missing values.(Hint : df.dropna(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f3f2d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ord_no  purch_amt    ord_date  customer_id\n",
       "5  70005.0    2400.60  2012-07-27       3001.0\n",
       "7  70010.0    1983.43  2012-10-10       3004.0\n",
       "8  70003.0    2480.40  2012-10-10       3003.0\n",
       "9  70012.0     250.45  2012-06-27       3002.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['ord_no','ord_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152b79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d958787",
   "metadata": {},
   "source": [
    "### Write a Pandas program to keep the valid entries of a given DataFrame.(Hint : df.dropna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "039001d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fff6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a7ae55c",
   "metadata": {},
   "source": [
    "### Write a Pandas program to calculate the total number of missing values in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9413a415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id\n",
       "0       NaN        NaN         NaN          NaN\n",
       "1       NaN     270.65  2012-09-10       3001.0\n",
       "2   70002.0      65.26         NaN       3001.0\n",
       "3       NaN        NaN         NaN          NaN\n",
       "4       NaN     948.50  2012-09-10       3002.0\n",
       "5   70005.0    2400.60  2012-07-27       3001.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0\n",
       "7   70010.0    1983.43  2012-10-10       3004.0\n",
       "8   70003.0    2480.40  2012-10-10       3003.0\n",
       "9   70012.0     250.45  2012-06-27       3002.0\n",
       "10      NaN      75.29  2012-08-17       3001.0\n",
       "11      NaN        NaN         NaN          NaN"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a6dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eeacb9f",
   "metadata": {},
   "source": [
    "### Write a Pandas program to replace NaNs with a single constant value in specified columns in a DataFrame.(Hint : df.fillna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1cfd412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4000.0\n",
       "1     3001.0\n",
       "2     3001.0\n",
       "3     4000.0\n",
       "4     3002.0\n",
       "5     3001.0\n",
       "6     3001.0\n",
       "7     3004.0\n",
       "8     3003.0\n",
       "9     3002.0\n",
       "10    3001.0\n",
       "11    4000.0\n",
       "Name: customer_id, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.customer_id.fillna(value=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a9f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36b2a26d",
   "metadata": {},
   "source": [
    "### Write a Pandas program to replace NaNs with the value from the previous row or the next row in a given DataFrame.(Hint : df.fillna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1d3be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "174fa3ee",
   "metadata": {},
   "source": [
    "### Write a Pandas program to replace NaNs with median or mean of the specified columns in a given DataFrame.(Hint : df.fillna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9098417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed484876",
   "metadata": {},
   "source": [
    "### Write a Pandas program to find the Indexes of missing values in a given DataFrame.(Hint : np.isnull().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5e40168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 11]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = list(df.customer_id.isnull().to_numpy().nonzero()[0])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a8141dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ord_no  purch_amt ord_date  customer_id\n",
       "0      NaN        NaN      NaN          NaN\n",
       "3      NaN        NaN      NaN          NaN\n",
       "11     NaN        NaN      NaN          NaN"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51a25bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.0</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.0</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.0</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.0</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.0</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ord_no  purch_amt    ord_date  customer_id\n",
       "0       NaN        NaN         NaN          NaN\n",
       "1       NaN     270.65  2012-09-10       3001.0\n",
       "2   70002.0      65.26         NaN       3001.0\n",
       "3       NaN        NaN         NaN          NaN\n",
       "4       NaN     948.50  2012-09-10       3002.0\n",
       "5   70005.0    2400.60  2012-07-27       3001.0\n",
       "6       NaN    5760.00  2012-09-10       3001.0\n",
       "7   70010.0    1983.43  2012-10-10       3004.0\n",
       "8   70003.0    2480.40  2012-10-10       3003.0\n",
       "9   70012.0     250.45  2012-06-27       3002.0\n",
       "10      NaN      75.29  2012-08-17       3001.0\n",
       "11      NaN        NaN         NaN          NaN"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168d17e",
   "metadata": {},
   "source": [
    "### Write a Pandas program to replace the missing values with the most frequent values present in each column of a given dataframe.(Hint : df.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "05501127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value=df.mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "be8e99ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_284401/1364442528.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.fillna(value=df.mean())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord_no</th>\n",
       "      <th>purch_amt</th>\n",
       "      <th>ord_date</th>\n",
       "      <th>customer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70002.000000</td>\n",
       "      <td>65.26</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70003.000000</td>\n",
       "      <td>270.65</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002.000000</td>\n",
       "      <td>65.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70010.000000</td>\n",
       "      <td>270.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70012.000000</td>\n",
       "      <td>948.50</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70005.000000</td>\n",
       "      <td>2400.60</td>\n",
       "      <td>2012-07-27</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70006.555556</td>\n",
       "      <td>5760.00</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70010.000000</td>\n",
       "      <td>1983.43</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70003.000000</td>\n",
       "      <td>2480.40</td>\n",
       "      <td>2012-10-10</td>\n",
       "      <td>3003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70012.000000</td>\n",
       "      <td>250.45</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>3002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>70006.555556</td>\n",
       "      <td>75.29</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>3001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>70006.555556</td>\n",
       "      <td>1324.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3001.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ord_no  purch_amt    ord_date  customer_id\n",
       "0   70002.000000      65.26  2012-09-10       3001.0\n",
       "1   70003.000000     270.65  2012-09-10       3001.0\n",
       "2   70002.000000      65.26         NaN       3001.0\n",
       "3   70010.000000     270.65         NaN       3001.7\n",
       "4   70012.000000     948.50  2012-09-10       3002.0\n",
       "5   70005.000000    2400.60  2012-07-27       3001.0\n",
       "6   70006.555556    5760.00  2012-09-10       3001.0\n",
       "7   70010.000000    1983.43  2012-10-10       3004.0\n",
       "8   70003.000000    2480.40  2012-10-10       3003.0\n",
       "9   70012.000000     250.45  2012-06-27       3002.0\n",
       "10  70006.555556      75.29  2012-08-17       3001.0\n",
       "11  70006.555556    1324.59         NaN       3001.7"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(value=df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f6f2c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ord_no       9 non-null      float64\n",
      " 1   purch_amt    11 non-null     float64\n",
      " 2   ord_date     9 non-null      object \n",
      " 3   customer_id  10 non-null     float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 512.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118bb2f",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1ad3c",
   "metadata": {},
   "source": [
    "## Create a hitmap for more information about the distribution of missing values in a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c1c5d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# # sns.heatmap(df.isna(), )\n",
    "# sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f3e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5d69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1bc103f",
   "metadata": {},
   "source": [
    "# Pandas - Assignment no 08\n",
    "- Here is link of [Pandas - Assignment no 08]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25950c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684dbde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b42609af",
   "metadata": {},
   "source": [
    "### [Project : Clean And Analyze Employee Exit Surveys](https://github.com/AnshuTrivedi/Data-Scientist-In-Python/blob/master/Projects/step_2/Course_4/Guided%20Project_Clean%20And%20Analyze%20Employee%20Exit%20Surveys.ipynb)\n",
    "\n",
    "**In this guided project, we'll work with exit surveys from employees of the Department of Education, Training and Employment) (DETE) and the Technical and Further Education (TAFE) institute in Queensland, Australia. You can find the TAFE exit survey here and the survey for the DETE here. We've made some slight modifications to these datasets to make them easier to work with, including changing the encoding to UTF-8 (the original ones are encoded using cp1252.)**\n",
    "\n",
    "\n",
    "\n",
    "Our end goal is to answer the following question:\n",
    "\n",
    "**Are employees who have only worked for the institutes for a short period of time resigning due to some kind of dissatisfaction? What about employees who have been at the job longer?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8dea0",
   "metadata": {},
   "source": [
    "#### Import the libraries and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa0780",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey = pd.read_csv('datasets/tafe_survey.csv')\n",
    "dete_survey = pd.read_csv('datasets/dete_survey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# birdeye view of dataset\n",
    "tafe_survey.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec1c38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get basic information of dataset\n",
    "tafe_survey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973edeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceadd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey = pd.read_csv('datasets/dete_survey.csv')\n",
    "dete_survey.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb86f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff58455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null/missing values into both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a9835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64120a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4132fcd",
   "metadata": {},
   "source": [
    "We can make the following observations based on the work above:\n",
    "- The dete_survey dataframe contains 'Not Stated' values that indicate values are missing, but they aren't represented as NaN.\n",
    "- Both the dete_survey and tafe_survey contain many columns that we don't need to complete our analysis.\n",
    "- Each dataframe contains many of the same columns, but the column names are different. There are multiple columns/answers that indicate an employee resigned because they were dissatisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6da0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f323fe9a",
   "metadata": {},
   "source": [
    "### Identify Missing Values and Drop Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2eaa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use the following columns from the `dete_dataset`\n",
    "\n",
    "dete_columns = ['ID', 'SeparationType', 'Cease Date', 'DETE Start Date',\n",
    "       'Role Start Date', 'Position', 'Classification', 'Region',\n",
    "       'Business Unit', 'Employment Status', 'Career move to public sector',\n",
    "       'Career move to private sector', 'Interpersonal conflicts',\n",
    "       'Job dissatisfaction', 'Dissatisfaction with the department',\n",
    "       'Physical work environment', 'Lack of recognition',\n",
    "       'Lack of job security', 'Work location', 'Employment conditions',\n",
    "       'Maternity/family', 'Relocation', 'Study/Travel', 'Ill Health',\n",
    "       'Traumatic incident', 'Work life balance', 'Workload',\n",
    "       'None of the above', 'Gender', 'Age', 'Aboriginal', 'Torres Strait',\n",
    "       'South Sea', 'Disability', 'NESB']\n",
    "# Read in the data again, but this time read `Not Stated` values as `NaN`\n",
    "\n",
    "dete_survey_updated = pd.read_csv('datasets/dete_survey.csv', usecols=dete_columns, na_values='Not Stated')\n",
    "dete_survey_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614313a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey_updated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just use the following columns from the `dete_dataset`\n",
    "\n",
    "tafe_columns = ['Record ID', 'Institute', 'WorkArea', 'CESSATION YEAR',\n",
    "       'Reason for ceasing employment',\n",
    "       'Contributing Factors. Career Move - Public Sector ',\n",
    "       'Contributing Factors. Career Move - Private Sector ',\n",
    "       'Contributing Factors. Career Move - Self-employment',\n",
    "       'Contributing Factors. Ill Health',\n",
    "       'Contributing Factors. Maternity/Family',\n",
    "       'Contributing Factors. Dissatisfaction',\n",
    "       'Contributing Factors. Job Dissatisfaction',\n",
    "       'Contributing Factors. Interpersonal Conflict',\n",
    "       'Contributing Factors. Study', 'Contributing Factors. Travel',\n",
    "       'Contributing Factors. Other', 'Contributing Factors. NONE',\n",
    "       'Gender. What is your Gender?', 'CurrentAge. Current Age',\n",
    "       'Employment Type. Employment Type', 'Classification. Classification',\n",
    "       'LengthofServiceOverall. Overall Length of Service at Institute (in years)',\n",
    "       'LengthofServiceCurrent. Length of Service at current workplace (in years)']\n",
    "\n",
    "# Read in the data again, but this time read `Not Stated` values as `NaN`\n",
    "tafe_survey_updated = pd.read_csv('datasets/tafe_survey.csv', usecols=tafe_columns, na_values='Not Stated')\n",
    "tafe_survey_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08077e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey_updated.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33143e8",
   "metadata": {},
   "source": [
    "#### Clean column names\n",
    "To clean the column names, following steps take place\n",
    "- convert upper case into lower case \n",
    "- remove left and right white spaces\n",
    "- remove white spaces with `-`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6fb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey_updated.columns =  dete_survey_updated.columns.str.lower().str.strip().str.replace(' ','_')\n",
    "dete_survey_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015af70",
   "metadata": {},
   "source": [
    "#### Update column names of `tafe_survey_updated` to match the names in dete_survey_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c028ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce1adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update column names to match the names in dete_survey_updated\n",
    "mapping = {'Record ID': 'id', 'CESSATION YEAR': 'cease_date', 'Reason for ceasing employment': 'separationtype', 'Gender. What is your Gender?': 'gender', 'CurrentAge. Current Age': 'age',\n",
    "       'Employment Type. Employment Type': 'employment_status',\n",
    "       'Classification. Classification': 'position',\n",
    "       'LengthofServiceOverall. Overall Length of Service at Institute (in years)': 'institute_service',\n",
    "       'LengthofServiceCurrent. Length of Service at current workplace (in years)': 'role_service'}\n",
    "tafe_survey_updated = tafe_survey_updated.rename(mapping, axis = 1)\n",
    "\n",
    "# Check that the specified column names were updated correctly\n",
    "tafe_survey_updated.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026537f4",
   "metadata": {},
   "source": [
    "### Filter the Data\n",
    "- Check the unique values for the `separationtype` column in both datasets\n",
    "- Update all separation types containing the word `resignation` in `dete_survey_updated` dataset to `Resignation`\n",
    "- Select only the `resignation` separation types from each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6621407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_survey_updated.separationtype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey_updated.separationtype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8596dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_survey_updated.separationtype =  dete_survey_updated.separationtype.str.split('-').str[0]\n",
    "dete_survey_updated.separationtype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg = dete_survey_updated[dete_survey_updated.separationtype == 'Resignation']\n",
    "tafe_reg =  tafe_survey_updated[tafe_survey_updated.separationtype == 'Resignation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960ed1b",
   "metadata": {},
   "source": [
    "> Note: `dete_reg` and `tafe_reg` are our final datasets for working on this project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c919c1d",
   "metadata": {},
   "source": [
    "### Verify the Data\n",
    "\n",
    "Now, before we start cleaning and manipulating the rest of our data, let's verify that the data doesn't contain any major inconsistencies (to the best of our knowledge). When you're working with real world data, don't assume that the data you're analyzing isn't corrupted in some way! Below, we clean and explore the `cease_date` and `dete_start_date` columns to make sure all of the years make sense. We'll use the following criteria:\n",
    "\n",
    "- Since the `cease_date` is the last year of the person's employment and the `dete_start_date` is the person's first year of employment, it wouldn't make sense to have years after the current date. Given that most people in this field start working in their 20s, it's also unlikely that the dete_start_date was before the year 1940.\n",
    "\n",
    "- Check the unique values of `cease_date`.\n",
    "- After that extract the years and convert them to a float type.\n",
    "- Check the unique values of `dete_start_date` and look for outliers.\n",
    "- Check the unique values of `cease_date` in `tafe_reg` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9e577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg.cease_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e32adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg.cease_date =  dete_reg.cease_date.str.split('/').str[-1]\n",
    "dete_reg.cease_date.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg.cease_date = dete_reg.cease_date.astype(float)\n",
    "dete_reg.cease_date.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5557f0",
   "metadata": {},
   "source": [
    "> **findings**: The years in both dataframes don't completely align. The `tafe_survey_updated` dataframe contains some cease dates in 2009, but the `dete_survey_updated` dataframe does not. The `tafe_survey_updated` dataframe also contains many more cease dates in 2010 than the `dete_survey_updaed` dataframe. Since we aren't concerned with analyzing the results by year, we'll leave them as is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4783c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7df0802",
   "metadata": {},
   "source": [
    "### Create a New Column\n",
    "Since our end goal is to answer the question below, we need a column containing the length of time an employee spent in their workplace, or years of service, in both dataframes.\n",
    "#### End goal: \n",
    "- Are employees who have only worked for the institutes for a short period of time resigning due to some kind of `dissatisfaction`? What about employees who have been at the job longer? The `tafe_resignations` dataframe already contains a `service` column, which we renamed to institute_service.\n",
    "\n",
    "#### Task:\n",
    "- we calculate the years of `service` in the `dete_survey_updated` dataframe by subtracting the `dete_start_date` from the `cease_date` and create a new column named institute_service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg['institute_service']= dete_reg.cease_date - dete_reg.dete_start_date\n",
    "dete_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd190c",
   "metadata": {},
   "source": [
    "### Identify Dissatisfied Employees\n",
    "\n",
    "Next, we'll identify any employees who resigned because they were dissatisfied. Below are the columns we'll use to categorize employees as \"dissatisfied\" from each dataframe:\n",
    "\n",
    "##### tafe_survey_updated:\n",
    "- Contributing Factors. Dissatisfaction\n",
    "- Contributing Factors. Job Dissatisfaction\n",
    "\n",
    "##### dafe_survey_updated:\n",
    "\n",
    "- job_dissatisfaction\n",
    "- dissatisfaction_with_the_department\n",
    "- physical_work_environment\n",
    "- lack_of_recognition\n",
    "- lack_of_job_security\n",
    "- work_location\n",
    "- employment_conditions\n",
    "- work_life_balance\n",
    "- workload\n",
    "\n",
    "#### Task : \n",
    "If the employee indicated any of the factors above caused them to resign, we'll mark them as dissatisfied in a new column. After our changes, the new dissatisfied column will contain just the following values:\n",
    "\n",
    "- True: indicates a person resigned because they were dissatisfied in some way\n",
    "- False: indicates a person resigned because of a reason other than dissatisfaction with the job\n",
    "- NaN: indicates the value is missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_reg['Contributing Factors. Dissatisfaction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_reg['Contributing Factors. Job Dissatisfaction'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce517fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vals(x):\n",
    "    if x=='-':\n",
    "        return False\n",
    "    elif pd.isnull(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be3d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_reg['dissatisfied'] = tafe_reg[['Contributing Factors. Dissatisfaction', 'Contributing Factors. Job Dissatisfaction']].applymap(update_vals).any(1, skipna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24553319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tafe_reg.dissatisfied.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the values in columns related to dissatisfaction to be either True, False, or NaN\n",
    "dete_reg['dissatisfied'] = dete_reg[['job_dissatisfaction',\n",
    "       'dissatisfaction_with_the_department', 'physical_work_environment',\n",
    "       'lack_of_recognition', 'lack_of_job_security', 'work_location',\n",
    "       'employment_conditions', 'work_life_balance',\n",
    "       'workload']].any(1, skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg['dissatisfied'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5c8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d97a2cc0",
   "metadata": {},
   "source": [
    "### Combine the Data\n",
    "\n",
    "Below, we'll add an institute column so that we can differentiate the data from each survey after we combine them. Then, we'll combine the dataframes and drop any remaining columns we don't nee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81942a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an institute column\n",
    "dete_reg['institute'] = 'DETE'\n",
    "tafe_reg['institute'] = 'TAFE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45834144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dete_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9706df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes\n",
    "combined = pd.concat([dete_reg, tafe_reg], ignore_index=True)\n",
    "\n",
    "# Verify the number of non null values in each column\n",
    "combined.notnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4bbc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with less than 500 non null values\n",
    "combined_updated = combined.dropna(thresh = 500, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60740",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_updated.notnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d469343",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_updated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37304c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_updated.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ecf87",
   "metadata": {},
   "source": [
    "### Clean the Service Column\n",
    "\n",
    "Next, we'll clean the institute_service column and categorize employees according to the following definitions:\n",
    "\n",
    "- New: Less than 3 years in the workplace\n",
    "- Experienced: 3-6 years in the workplace\n",
    "- Established: 7-10 years in the workplace\n",
    "- Veteran: 11 or more years in the workplace\n",
    "\n",
    "#### Task : \n",
    "- Check the unique values of `institute_service` \n",
    "- Extract the years of service and convert the type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180878b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_updated.institute_service.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the years of service and convert the type to float\n",
    "combined_updated['institute_service_up'] = combined_updated['institute_service'].astype('str').str.extract(r'(\\d+)')\n",
    "combined_updated['institute_service_up'] = combined_updated['institute_service_up'].astype('float')\n",
    "\n",
    "# Check the years extracted are correct\n",
    "combined_updated['institute_service_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert years of service to categories\n",
    "def transform_service(val):\n",
    "    if val >= 11:\n",
    "        return \"Veteran\"\n",
    "    elif 7 <= val < 11:\n",
    "        return \"Established\"\n",
    "    elif 3 <= val < 7:\n",
    "        return \"Experienced\"\n",
    "    elif pd.isnull(val):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return \"New\"\n",
    "combined_updated['service_cat'] = combined_updated['institute_service_up'].apply(transform_service)\n",
    "\n",
    "# Quick check of the update\n",
    "combined_updated['service_cat'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1c037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00f2b186",
   "metadata": {},
   "source": [
    "### Perform Initial Analysis\n",
    "\n",
    "Finally, we'll replace the missing values in the `dissatisfied` column with the most frequent value, `False`. Then, we'll calculate the percentage of employees who resigned due to dissatisfaction in each `service_cat` group and `plot` the results.\n",
    "\n",
    "Note that since we still have additional missing values left to deal with, this is meant to be an initial introduction to the analysis, not the final analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9138eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the unique values\n",
    "combined_updated['dissatisfied'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with the most frequent value, False\n",
    "combined_updated['dissatisfied'] = combined_updated['dissatisfied'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b32ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_updated.service_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of employees who resigned due to dissatisfaction in each category\n",
    "dis_pct = combined_updated.pivot_table(index='service_cat', values='dissatisfied')\n",
    "dis_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f6d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "%matplotlib inline\n",
    "dis_pct.plot(kind='bar', rot=30, figsize=(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcf2cc",
   "metadata": {},
   "source": [
    "> **Note** : From the initial analysis above, we can tentatively conclude that employees with 7 or more years of service are more likely to resign due to some kind of dissatisfaction with the job than employees with less than 7 years of service. However, we need to handle the rest of the missing data to finalize our analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cc2fb",
   "metadata": {},
   "source": [
    "In this guided project, we experienced that in order to extract any meaningful insights from our data, we had to perform many data cleaning tasks. In order to create one visualization (and not even the final one), we completed the following tasks:\n",
    "\n",
    "- Explored the data and figured out how to prepare it for analysis\n",
    "- Corrected some of the missing values\n",
    "- Dropped any data not needed for our analysis\n",
    "- Renamed our columns\n",
    "- Verified the quality of our data\n",
    "- Created a new institute_service column\n",
    "- Cleaned the Contributing Factors columns\n",
    "- Created a new column indicating if an employee resigned because they were dissatisfied in some way\n",
    "- Combined the data\n",
    "- Cleaned the institute_service column\n",
    "- Handled the missing values in the dissatisfied column\n",
    "- Aggregated the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608dbf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
