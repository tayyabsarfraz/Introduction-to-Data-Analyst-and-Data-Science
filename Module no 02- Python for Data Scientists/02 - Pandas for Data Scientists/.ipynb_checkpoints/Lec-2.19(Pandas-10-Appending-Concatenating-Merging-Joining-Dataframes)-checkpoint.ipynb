{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a87b5ef",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<h1 align=\"center\">Introduction to Data Analyst and Data Science for beginners</h1>\n",
    "<h1 align=\"center\">Lecture no 2.19(Pandas-10)</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Ehtisham Sadiq</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f82705",
   "metadata": {},
   "source": [
    "## _Merging, Joining, Concatenating and Appending Dataframes_\n",
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/pandas-apps.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a90b6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12db95e1",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "\n",
    "**PART-I: (Merging and Joining)**\n",
    "1. Merging DataFrames using `pd.merge()` method\n",
    "   - Perform **Inner Join** (which is default)\n",
    "   - Peform **Outer**/**Full Outer Join**\n",
    "   - Perform **Left Outer Join**\n",
    "   - Perform **Right Outer Join**<br><br>\n",
    "2. Additional Parameters to `pd.merge()` Method  \n",
    "   - Use of `indicator` parameter to indicate the df to which the value belong\n",
    "   - Use of `suffixes` parameter to differentiate between common column labels\n",
    "   - Use of `validate` parameter to check for duplicate keys\n",
    "   \n",
    "**PART-II: (Concatenating and Appending)**    \n",
    "\n",
    "3. Row wise Concatenation using `pd.concat()`\n",
    "\n",
    "4. Column wise Concatenation using `pd.concat()`\n",
    "\n",
    "5. Adding a Single Row/Column in a Dataframe using `pd.concat()`\n",
    "\n",
    "6. Appending Dataframes using `df.append()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c142c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b820b858",
   "metadata": {},
   "source": [
    "# Part-I (Merging and Joining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b919365a",
   "metadata": {},
   "source": [
    "## 1. Merging DataFrames using `pd.merge()` Method\n",
    "Pandas `pd.merge()` is a versatile method to perform all standard database join operations between DataFrame or named Series objects.\n",
    "\n",
    "```\n",
    "pd.merge(left, right, how=\"inner\", indicator=False, on=None, suffixes=(\"_x\", \"_y\"), validate=None)\n",
    "```\n",
    "Where,\n",
    "- **`left`:** A DataFrame or named Series object.\n",
    "- **`right`:** Another DataFrame or named Series object.\n",
    "- **`how`:** specifies the type of join {`inner`, `outer`, `left`, `right`} (default is `inner`)\n",
    "- **`on`:** Column or index level names to join on. Must be found in both the left and right DataFrame and/or Series objects. \n",
    "- **`indicator`:** If set to True, adds a column to the output DataFrame called **`_merge`** with information on the source of each row {`left_only` means, this element is present only in left Dataframe, `right_only` means this is present only in right dataframe, `both` means they are present in both\n",
    "- **`suffixes`:** A tuple of string suffixes to apply to overlapping columns. Defaults to ('_x', '_y').\n",
    "- **`validate`:** If specified, checks for uniqueness of keys. This parameter can take following four values (default is None):\n",
    "    - “one_to_one” or “1:1”: checks if merge keys are unique in both left and right datasets.\n",
    "    - “one_to_many” or “1:m”: checks if merge keys are unique in left dataset.\n",
    "    - “many_to_one” or “m:1”: checks if merge keys are unique in right dataset.\n",
    "    - “many_to_many” or “m:m”: allowed, but does not result in checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff27b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6946785c",
   "metadata": {},
   "source": [
    "### a. Inner  Join:\n",
    "\n",
    "It is the most common type of join you’ll be working with. It returns a dataframe with only those rows that have common characteristics.\n",
    "An inner join requires each row in the two joined dataframes to have matching column values. This is similar to the intersection of two sets.\n",
    "\n",
    "<img align=\"center\" width=\"900\" height=\"600\"  src=\"images/join-inner.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573706e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d880f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us create a simple data frame\n",
    "import pandas as pd\n",
    "\n",
    "# This dataframe doesn't have entry for Lahore\n",
    "df_temp = pd.DataFrame({\n",
    "    'city': ['Lahore', 'Muree', 'Peshawer', 'Sialkot'],\n",
    "    'temperature' : [39, 14, 29, 32],\n",
    "})\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This Dataframe has an extra entry for Multan\n",
    "df_hum = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Lahore', 'Peshawer', 'Lahore', 'Muree'],\n",
    "    'humidity' : [76, 95, 72, 70, 75],\n",
    "})\n",
    "df_hum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4de6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e1325d0",
   "metadata": {},
   "source": [
    "**Note the column `city` on which we want to perform an inner join, in the two dataframes has only four cities in common. So the resulting dataframe will have only four rows that are common in both dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce070",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.merge(df_temp, df_hum, how='inner')\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge will perform only for those cities that are common in both, which means it by-default performs inner-join\n",
    "d1 = pd.merge(df_temp, df_hum, on='city', how = 'inner', indicator=True)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb58d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note only the sequence of o/p dataframe changes once we change the order in case of inner join\n",
    "d1 = pd.merge(df_hum, df_temp, on='city', how = 'inner', indicator=True)\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378c092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "965cd00c",
   "metadata": {},
   "source": [
    "### b. Full Join:\n",
    "Also known as Full Outer Join, returns all those records which either have a match in the left or right dataframe. This is similar to the union of two sets.\n",
    "\n",
    "<img align=\"center\" width=\"900\" height=\"600\"  src=\"images/join-fullouter.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0033b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c49c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame({\n",
    "    'city': ['Lahore', 'Muree', 'Peshawer', 'Sialkot'],\n",
    "    'temperature' : [39, 14, 29, 32],\n",
    "})\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d45d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hum = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Lahore', 'Peshawer', 'Lahore', 'Muree'],\n",
    "    'humidity' : [76, 95, 72, 70, 75],\n",
    "})\n",
    "df_hum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015bf262",
   "metadata": {},
   "source": [
    "**Note the column `city` on which we want to perform a full outer join, in the two dataframes has a union of  seven cities. So the resulting dataframe will have seven rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6531e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.merge(df_temp, df_hum, on='city', how='outer', indicator=True)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a594b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note only the sequence of o/p dataframe changes once we change the order in case of inner join\n",
    "d3 = pd.merge(df_hum, df_temp, on='city', how='outer', indicator=True)\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dfad95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117ae3fb",
   "metadata": {},
   "source": [
    "###  c. Left Join\n",
    "Also known as Left outer join. It is simply performs an inner join plus all the non-matching rows of the left dataframe are taken as it is filled with NaN for columns of the right dataframe.\n",
    "\n",
    "<img align=\"center\" width=\"900\" height=\"600\"  src=\"images/join-leftouter.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfc333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame({\n",
    "    'city': ['Lahore', 'Muree', 'Peshawer', 'Sialkot'],\n",
    "    'temperature' : [39, 14, 29, 32],\n",
    "})\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hum = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Lahore', 'Peshawer', 'Lahore', 'Muree'],\n",
    "    'humidity' : [76, 95, 72, 70, 75],\n",
    "})\n",
    "df_hum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1565198",
   "metadata": {},
   "source": [
    "**Note the column `city` on which we want to perform a left outer join, in the two dataframes has an intersection of four rows. Other than these four rows, record of city Sialkot from left dataframe will also be included in the resulting dataframe being a left outer join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In left outer join, it takes all the rows from left dataframe and only common rows from right dataframe\n",
    "d3 = pd.merge(df_temp, df_hum, on='city', how='left', indicator=True)\n",
    "d3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516c5e5a",
   "metadata": {},
   "source": [
    "**Left and right outer join also depend on the order of Dataframes that are passed to merge() function. Let us change the order and understand this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1050bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = pd.merge(df_hum, df_temp, on='city', how='left', indicator=True)\n",
    "d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6d366a5",
   "metadata": {},
   "source": [
    "### d. Right  Join\n",
    "Also known as Right outer join. It is simply performs an inner join plus  all the non-matching rows of the right dataframe are taken as it is filled with NaN for columns of the left dataframe.\n",
    "\n",
    "<img align=\"center\" width=\"900\" height=\"600\"  src=\"images/join-rightouter.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame({\n",
    "    'city': ['Lahore', 'Muree', 'Peshawer', 'Sialkot'],\n",
    "    'temperature' : [39, 14, 29, 32],\n",
    "})\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hum = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Lahore', 'Peshawer', 'Lahore', 'Muree'],\n",
    "    'humidity' : [76, 95, 72, 70, 75],\n",
    "})\n",
    "df_hum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2fad33",
   "metadata": {},
   "source": [
    "**Note the column `city` on which we want to perform a right outer join, in the two dataframes has an intersection of four rows. Other than these four rows, record of city Karachi from right dataframe will also be included in the resulting dataframe being a right outer join**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Right outer join, it takes all the rows from Right dataframe and only common rows from left dataframe\n",
    "df3 = pd.merge(df_temp, df_hum, on='city', how='right', indicator=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b2254",
   "metadata": {},
   "source": [
    "**Left and right outer join also depend on the order of Dataframes that are passed to merge() function. Let us change the order and understand this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff470642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.merge(df_hum, df_temp, on='city', how='right', indicator=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a1129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5a5458",
   "metadata": {},
   "source": [
    "## 2. Additional Parameters to `pd.merge()` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff418a6",
   "metadata": {},
   "source": [
    "####  Use of `suffixes` Parameter\n",
    "- When you merge dataframes having columns with same labels, other than the one on which you are joining ('city`)\n",
    "- The resulting dataframe will have appended suffixes (`_x`, `_y`) with column labels to differentiate b/w columns of both dataframes\n",
    "- For better understanding you can pass `suffixes`.....\n",
    "- Let us understand this by example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer'],\n",
    "    'temperature' : [35, 39, 33],\n",
    "    'humidity' : [76, 95, 72]\n",
    "})\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5092f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Peshawer', 'Islamabad'],\n",
    "    'temperature' : [41, 44, 47],\n",
    "    'humidity' : [88, 99, 79]\n",
    "})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on='city', how='inner')\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d02e8",
   "metadata": {},
   "source": [
    "- **Note that `merge` has automatically appended suffixes with column labels to differentiate b/w columns of both dataframes**\n",
    "- **You can use the `suffixes` parameter to `pd.merge()` method to specify the suffixes other than `_x` and `_y` to something more meaningful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = pd.merge(df1, df2, on='city', how='inner', suffixes=('_left','_right'))\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf67c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40ee79f2",
   "metadata": {},
   "source": [
    "####  Use `validate` Parameter to Check for Duplicate Keys\n",
    "- We can use the `validate` parameter to the `pd.merge()` method to check for uniqueness of keys. This parameter can take following four values (default is None):\n",
    "    - `one_to_one` or `1:1`: checks if merge keys are unique in both left and right datasets.\n",
    "    - `one_to_many` or `1:m`: checks if merge keys are unique in left dataset.\n",
    "    - `many_to_one` or `m:1`: checks if merge keys are unique in right dataset.\n",
    "    - `many_to_many` or `m:m`: allowed, but does not result in checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Muree'],\n",
    "    'temperature' : [35, 39, 15],\n",
    "})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53191111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Islamabad', 'Lahore'],\n",
    "    'humidity' : [76, 95, 72, 76],\n",
    "})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfaf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df3cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd6257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([df1, df2] , ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91661194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df1, df2], join='outer', ignore_index=True )\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6095db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30f82f5f",
   "metadata": {},
   "source": [
    ">**`one_to_one` or `1:1`: checks if merge keys are unique in both left and right dataframes, if not then throw exception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(df1, df2, on='city', how='outer', validate='one_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52715b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4c42a0",
   "metadata": {},
   "source": [
    ">**`one_to_many` or `1:m`: checks if merge keys are unique in left dataframe, if not then throw exception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033124a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd4d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(df1, df2, on='city', how='outer', validate='one_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb94bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839c38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4cab63d",
   "metadata": {},
   "source": [
    ">**`many_to_one` or `m:1`: checks if merge keys are unique in right dataframe, if not then throw exception**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.merge(df1, df2, on='city', how='outer', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56a98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e7f5c9",
   "metadata": {},
   "source": [
    ">**`many_to_many` or `m:m`: No checks are performed on keys uniqueness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9f59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fd043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='city', how='outer', validate='many_to_many')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdeaa8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d035c8",
   "metadata": {},
   "source": [
    "# Part-II (Concatenating and Appending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826751f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e26ad476",
   "metadata": {},
   "source": [
    "## Concatenation of  DataFrames (Row Wise + Column Wise)\n",
    "\n",
    "<img align=\"left\" width=\"350\" height=\"90\"  src=\"images/row.PNG\"  >\n",
    "<img align=\"right\" width=\"490\" height=\"100\"  src=\"images/concat_2.png\" >\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "- The `pd.concat()` method is used to concat pandas objects along a particular axis with optional set logic along the other axes. \n",
    "```\n",
    "pd.concat(objs, axis=0, join='outer', ignore_index=False, keys=None, verify_integrity=False)\n",
    "```\n",
    "\n",
    "Where,\n",
    "- `objs`: a sequence or mapping of Series or DataFrame objects\n",
    "- `axis`: The axis to concatenate along. {0/’index’, 1/’columns’}, default 0\n",
    "- `join`{‘inner’, ‘outer’}, Default is `outer` for union. If `inner` that means intersection\n",
    "- `ignore_index`: If True, the resulting axis will be labeled 0, …, n - 1. This is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. (default is False)\n",
    "- `keys`: sequence, default None (Construct hierarchical index using the passed keys as the outermost level.)\n",
    "- `verify_integrity` : boolean, default False. Check whether the new concatenated axis contains duplicates. This can be very expensive relative to the actual data concatenation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feecd6b4",
   "metadata": {},
   "source": [
    "## 3. Row-Wise Concatenation\n",
    "<img align=\"left\" width=\"350\" height=\"90\"  src=\"images/row.PNG\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Pak_Weather = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    'humidity' : [76, 95, 72, 81, 70],\n",
    "})\n",
    "Pak_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb91c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "UAE_Weather = pd.DataFrame({\n",
    "    'city': [ 'Dubai', 'Sharja', 'Ajman', 'Abu Dhabi'],\n",
    "    'temperature' : [41, 44, 47, 45],\n",
    "    'humidity' : [88, 99, 79, 86],\n",
    "})\n",
    "UAE_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat([Pak_Weather, UAE_Weather], join='outer' )\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473f4e0",
   "metadata": {},
   "source": [
    "#### Concatenate Dataframes (row-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a1462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat([Pak_Weather, UAE_Weather])\n",
    "df1 = pd.concat([Pak_Weather, UAE_Weather], axis=0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e545d4f",
   "metadata": {},
   "source": [
    "- Notice the index is also concatenated as such\n",
    "- To handle this pass `ignore_index` parameter a value of `True`, so that the resulting axis is be labeled 0, …, n - 1. \n",
    "- Useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information.\n",
    "- Note the index values on the other axes (i.e., columns) have still respected in the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([Pak_Weather,UAE_Weather], axis=0, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4389cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a45239",
   "metadata": {},
   "source": [
    "- Other than the numeric index, if you want to have an additional index for your sub groups, you can use the `keys` argument to `pd.concat()` method\n",
    "- It provides multi-indexing\n",
    "- Remember this will work only if the `ignore_index` argument is `False` which is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([Pak_Weather, UAE_Weather], axis=0, keys=[\"city\",])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0424d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([Pak_Weather, UAE_Weather], axis=0, keys=[\"Pak\", \"UAE\"])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f40f1",
   "metadata": {},
   "source": [
    "- The advantage of doing this is you can use `df.loc` to get a subset of your dataframe\n",
    "- So, after getting a big dataframe if you want to get the dataframe from which it was created keys arg is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['Pak', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb637708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc['UAE', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96c379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98968442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1be4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6138a715",
   "metadata": {},
   "source": [
    "#### What will Happen if one of the Dataframe has an Additional Column\n",
    "- If you combine two Dataframe objects which do not have all the same columns, then the columns outside the intersection will be filled with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fb7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pak_Weather = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    \n",
    "})\n",
    "Pak_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25490022",
   "metadata": {},
   "outputs": [],
   "source": [
    "UAE_Weather = pd.DataFrame({\n",
    "    'city': [ 'Dubai', 'Sharja', 'Ajman', 'Abu Dhabi'],\n",
    "    'temperature' : [41, 44, 47, 45],\n",
    "    'humidity' : [88, 99, 79, 86],\n",
    "})\n",
    "UAE_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN will be placed where values are missing\n",
    "df = pd.concat([Pak_Weather,UAE_Weather], axis=0, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e303b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff090a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756791b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214dbb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa0954ac",
   "metadata": {},
   "source": [
    "## 4. Column Wise Concatenation\n",
    "- It is not advised to concatenate dataframes column wise. If you want to then you need to take care of some checks like:\n",
    "    - the number of rows must be same in both dataframes, and\n",
    "    - Indexes of both dataframes are sorted\n",
    "- If you are done with all the checks then you can simply use `axis=1` to do the job.\n",
    "\n",
    "<img align=\"left\" width=\"490\" height=\"100\"  src=\"images/concat_2.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d7dcf",
   "metadata": {},
   "source": [
    "### a. Creating a two Simple Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f961d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "})\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8344bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_df = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'wind speed' : [9, 12, 7, 13, 18],\n",
    "})\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2288f3",
   "metadata": {},
   "source": [
    "### b. Concatenate Dataframes (column-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to use the argument axis=1\n",
    "df = pd.concat([temp_df,wind_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd40a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e46f0d9d",
   "metadata": {},
   "source": [
    "### c. What will happen if we have missing data in our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe do not have the temperature for Lahore\n",
    "temp_df = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [39, 33, 29, 15],\n",
    "})\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b39323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataframe do not have the windspeed of Islamabad\n",
    "wind_df = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Muree'],\n",
    "    'wind speed' : [9, 12, 7, 18],\n",
    "})\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469a354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.concat([temp_df,wind_df], axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7b9b6",
   "metadata": {},
   "source": [
    "**This doesnot look correct**\n",
    "- We have missing data in the resulting dataframe, i.e., it does not contain record for Lahore, which was there in the second dataframe but not in the first\n",
    "- Solution is while creating the dataframe you pass it the index\n",
    "- In Pandas, while creating a DataFrame, you can pass the index argument with appropriate related indices, which is a way to align rows from different dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8700fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataframe do not have the temperature for Lahore\n",
    "temp_df = pd.DataFrame({\n",
    "    'city': [ 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [39, 33, 29, 15],\n",
    "},index=[0,1,2,3])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataframe do not have the windspeed of Islamabad\n",
    "# Note the indices in wind_df are related to indices of temp_df\n",
    "wind_df = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Muree'],\n",
    "    'wind speed' : [9, 12, 7, 18],\n",
    "}, index=[4,0,1,3])\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ca5b9",
   "metadata": {},
   "source": [
    "---\n",
    "#### Note the indexes in above two dataframes match. Now concatenation will be OK\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([temp_df,wind_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3306da",
   "metadata": {},
   "source": [
    ">- Concatenating Dataframes along axis = 1 adds one Dataframe along the other. It is like a full outer join. Placing NaN for non-matching rows in the left as well as right Dataframes.\n",
    ">- By default, a concatenation results in a set union, where all data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339166b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea8276dd",
   "metadata": {},
   "source": [
    "## 5. Adding a Single Row/Column in a Dataframe\n",
    "- Now let us see how we can concat a single row or a single column to a dataframe using the `pd.concat()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e80c9",
   "metadata": {},
   "source": [
    "### a. Adding a Row in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969be5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    'humidity' : [76, 95, 72, 81, 70],\n",
    "})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"city\": \"Multan\", \"temperature\": 45, \"humidity\": 75}, index=[5])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca835d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbed946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2], ignore_index=True, axis = 0)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee8c26",
   "metadata": {},
   "source": [
    ">**You can place the new row at your desired location using slicing operator, as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1[:2], df2, df1[2:]], ignore_index = True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fcac05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0bb80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58a3ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4b7432b",
   "metadata": {},
   "source": [
    "### b. Adding a Column in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pak_Weather = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    'humidity' : [76, 95, 72, 81, 70],\n",
    "})\n",
    "Pak_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18946847",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([\"Humid\", 'Dry', 'Rainy', 'Humid', 'Rainy'], name=\"event\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddbf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([Pak_Weather, s], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864c0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f919f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab483930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9af9231d",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"310\" height=\"100\"  src=\"images/append.png\"  >\n",
    "\n",
    "## 6. Appending DataFrames\n",
    "- The `df1.append(df2)` method is used to concat the second dataframe’s records at the end of first dataframe (along axis=0). Columns not present in the first DataFrame are added as new columns\n",
    "- The `df1.append(df2)` method considers the calling dataframe as main object and adds rows to that dataframe from the dataframes that are passed to the function as argument.\n",
    "- It returns a new dataframe object consisting of the rows of caller and the rows of `other`. The dataframe that called the `append()` method,  remain unchanged.\n",
    "```\n",
    "df.append(other, ignore_index=False, verify_integrity=False, sort=False)\n",
    "```\n",
    "\n",
    "    - `other`: DataFrame or Series/dict-like object, or list of these (The data to append.)\n",
    "    - `ignore_index`: If True, the resulting axis will be labeled 0, 1, …, n - 1 (default is False)\n",
    "    - `verify_integrity`: If True, raise ValueError on creating index with duplicates (default is False)\n",
    "    - `sort`: Sort columns if the columns of `self` and `other` are not aligned (default is False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5cc5d3",
   "metadata": {},
   "source": [
    "### a. Append Two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pak_Weather = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    'humidity' : [76, 95, 72, 81, 70],\n",
    "})\n",
    "Pak_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae4f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "UAE_Weather = pd.DataFrame({\n",
    "    'city': [ 'Dubai', 'Sharja', 'Ajman', 'Abu Dhabi'],\n",
    "    'temperature' : [41, 44, 47, 45],\n",
    "    'humidity' : [88, 99, 79, 86],\n",
    "})\n",
    "UAE_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append Dataframe\n",
    "df2 =  Pak_Weather.append(UAE_Weather)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd5966",
   "metadata": {},
   "source": [
    "- Notice the index is also concatenated as such\n",
    "- To handle this pass `ignore_index` parameter a value of `True`, so that the resulting axis is be labeled 0, …, n - 1. \n",
    "- Useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17da324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the ignore_index to true\n",
    "df2 =  Pak_Weather.append(UAE_Weather, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1126bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac0b6a94",
   "metadata": {},
   "source": [
    "### b. Append a Row in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11741128",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pak_Weather = pd.DataFrame({\n",
    "    'city': [ 'Lahore', 'Karachi', 'Peshawer', 'Islamabad', 'Muree'],\n",
    "    'temperature' : [35, 39, 33, 29, 15],\n",
    "    'humidity' : [76, 95, 72, 81, 70],\n",
    "})\n",
    "Pak_Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67aafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a row to be appended\n",
    "d1 = pd.DataFrame({\"city\": \"Multan\", \"temperature\": 45, \"humidity\": 75}, index=[5])\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append this dataframe having single row to Pak_Weather dataframe\n",
    "df3 =  Pak_Weather.append(d1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e23b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a148f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a463c667",
   "metadata": {},
   "source": [
    "**Columns of passed/other dataframe that are not in the caller are added as new columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61338b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame({\"city\": \"Sialkot\", \"temperature\": 45, \"humidity\": 75, \"newcol\": 66}, index=[5])\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 =  Pak_Weather.append(d1)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80aad23e",
   "metadata": {},
   "source": [
    "## Practice Exercise no 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ced9cc",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "#### Housing Market\n",
    "This time we will create our own dataset with fictional numbers to describe a house market. As we are going to create random data don't try to reason of the numbers.\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6519151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68cca7c",
   "metadata": {},
   "source": [
    "### Step 2. Create 3 differents Series, each of length 100, as follows: \n",
    "1. The first a random number from 1 to 4 \n",
    "2. The second a random number from 1 to 3\n",
    "3. The third a random number from 10,000 to 30,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2fb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# series1 =pd.Series(np.random.randint(1,5,100))\n",
    "# series2 =pd.Series(np.random.randint(1,4,100))\n",
    "# series3 =pd.Series(np.random.randint(10000,30001,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126790a",
   "metadata": {},
   "source": [
    "### Step 3. Let's create a DataFrame by joinning the Series by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab6461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([series1,series2,series3], axis=1)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27159cac",
   "metadata": {},
   "source": [
    "### Step 4. Change the name of the columns to bedrs, bathrs, price_sqr_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb85608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={0:'bedrs',1:'bathrs',2:'price_sqr_meter'})\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b719c1f",
   "metadata": {},
   "source": [
    "### Step 5. Create a one column DataFrame with the values of the 3 Series and assign it to 'bigcolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigcolumn = pd.concat([series1,series2,series3], axis=0)\n",
    "# bigcolumn.head()\n",
    "\n",
    "# # it is still a series, we need to transform it into dataframe\n",
    "# bigcolumn = bigcolumn.to_frame()\n",
    "# bigcolumn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10759fb",
   "metadata": {},
   "source": [
    "### Step 6. Oops, it seems it is going only until index 99. Is it true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # No it is not true, the length of dataframe of 300\n",
    "# len(bigcolumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a57c73",
   "metadata": {},
   "source": [
    "### Step 7. Reindex the DataFrame so it goes from 0 to 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181233bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigcolumn.reset_index(drop=True, inplace=True)\n",
    "# bigcolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de530ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6c955d",
   "metadata": {},
   "source": [
    "## Practice Exercise no 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d159ce",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "#### Fictitious Names\n",
    "This time you will create a data again \n",
    "In order to understand about it go to [here](https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/).\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df80e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a19059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04bc2762",
   "metadata": {},
   "source": [
    "### Step 2. Create the 3 DataFrames based on the following raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_1 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'], \n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "\n",
    "raw_data_2 = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'], \n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "\n",
    "raw_data_3 = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd88399",
   "metadata": {},
   "source": [
    "### Step 3. Assign each to a variable called data1, data2, data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.DataFrame(raw_data_1)\n",
    "# data2 = pd.DataFrame(raw_data_2)\n",
    "# data3 = pd.DataFrame(raw_data_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2441a",
   "metadata": {},
   "source": [
    "### Step 4. Join the two dataframes(data1, data2) along rows and assign  to all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pd.concat([data1,data2])\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30593f6",
   "metadata": {},
   "source": [
    "### Step 5. Join the two dataframes along columns and assing to all_data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_col = pd.concat([data1,data2],axis=1)\n",
    "# all_data_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae5d76",
   "metadata": {},
   "source": [
    "### Step 6. Print data3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d87782",
   "metadata": {},
   "source": [
    "### Step 7. Merge `all_data` and `data3` along the `subject_id` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf21629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(all_data, data3, on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c19c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c322916",
   "metadata": {},
   "source": [
    "### Step 8. Merge only the data that has the same 'subject_id' on both data1 and data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8534ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(data1,data2,on='subject_id', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e398c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d4fba1",
   "metadata": {},
   "source": [
    "### Step 9. Merge all values in data1 and data2 along subject_id, with matching records from both sides where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa77428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(data1,data2,on='subject_id', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7df4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bfe002b",
   "metadata": {},
   "source": [
    "## Practice Exercise no 03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e25bbc5",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "#### MPG Cars\n",
    "\n",
    "The following exercise utilizes data from [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Auto+MPG)\n",
    "\n",
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d29bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bcd6b0",
   "metadata": {},
   "source": [
    "### Step 2. Import the first dataset [cars1](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/cars1.csv) and [cars2](https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/cars2.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/cars1.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/bsef19m521/DatasetsForProjects/master/cars2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car1 = pd.read_csv(url1)\n",
    "# car2 = pd.read_csv(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807c8ed",
   "metadata": {},
   "source": [
    "### Step 4. Oops, it seems our first dataset has some unnamed blank columns, fix cars1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car1 = car1.loc[:,\"mpg\":\"car\"]\n",
    "# car1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd521d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfcab72d",
   "metadata": {},
   "source": [
    "### Step 5. What is the number of observations in each dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"car1.shape : \", car1.shape)\n",
    "# print(\"car2.shape : \", car2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36ab41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b155310c",
   "metadata": {},
   "source": [
    "### Step 6. Join cars1 and cars2 into a single DataFrame called cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars = pd.concat([car1,car2]).reset_index(drop=True)\n",
    "# cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ddf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7b0d7fa",
   "metadata": {},
   "source": [
    "### Step 7. Oops, there is a column missing, called owners. Create a random number Series from 15,000 to 73,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b07669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# owners = pd.Series(np.random.randint(15000,73001,398), dtype=np.uint32)\n",
    "# owners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c719f9c",
   "metadata": {},
   "source": [
    "### Step 8. Add the column owners to cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb0231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars['owners'] = owners\n",
    "# cars.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce749c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e275e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "317c4921",
   "metadata": {},
   "source": [
    "## Check Your Concepts:\n",
    "- What is Pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d0a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5f1e364",
   "metadata": {},
   "source": [
    "# Pandas - Assignment no 10\n",
    "- Here is link of Pandas - [Assignment no 10]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10076e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41958314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51825458",
   "metadata": {},
   "source": [
    "### [Project : Analyzing NYC High School Data](https://github.com/AnshuTrivedi/Data-Scientist-In-Python/blob/master/Projects/step_2/Course_6/Guided%20Project_Analyzing%20NYC%20High%20School%20Data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676e3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ce01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0475485",
   "metadata": {},
   "source": [
    "### [Project : Star Wars Survey](https://github.com/AnshuTrivedi/Data-Scientist-In-Python/blob/master/Projects/step_2/Course_6/Guided%20Project_Star%20Wars%20Survey.ipynb)\n",
    "**While waiting for Star Wars: The Force Awakens to come out, the team at FiveThirtyEight became interested in answering some questions about Star Wars fans. In particular, they wondered: does the rest of America realize that “The Empire Strikes Back” is clearly the best of the bunch?\n",
    "The team needed to collect data addressing this question. To do this, they surveyed Star Wars fans using the online tool SurveyMonkey. They received 835 total responses, which you download from their GitHub repository.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe193eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
