{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc72fe3",
   "metadata": {},
   "source": [
    "---   \n",
    "\n",
    "<h1 align=\"center\">Introduction to Data Analyst and Data Science for beginners</h1>\n",
    "<h1 align=\"center\">Lecture no 2.13(Pandas-04)</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Ehtisham Sadiq</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de11ce0",
   "metadata": {},
   "source": [
    "## _IO with CSV EXCEL and JSON Files_\n",
    "\n",
    "<img align=\"center\" width=\"600\" height=\"150\"  src=\"images/fileformats.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b992d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "441aebbc",
   "metadata": {},
   "source": [
    "#### Read Pandas Documentation:\n",
    "- General Info: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html\n",
    "\n",
    "\n",
    "- For `read_csv`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv#pandas.read_csv\n",
    "\n",
    "\n",
    "- For `read_excel`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html?highlight=read_excel#pandas.read_excel\n",
    "\n",
    "\n",
    "- For `read_json`:https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.io.json.read_json.html?highlight=pandas%20read_json#pandas.io.json.read_json\n",
    "\n",
    "\n",
    "- For `to_csv`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html#pandas.DataFrame.to_csv\n",
    "\n",
    "\n",
    "\n",
    "- For `to_excel`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html?highlight=to_excel#pandas.DataFrame.to_excel\n",
    "\n",
    "\n",
    "- For `to_json`: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html?highlight=to_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dcd278",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "[Pandas](https://pandas.pydata.org/) provides helper functions to read data from various file formats like CSV, EXCEL, JSON, HTML, SQL table, and many more.\n",
    "1. Reading data from a CSV/TSV File\n",
    "2. Reading a CSV file from a Remote System\n",
    "3. Writing Contents of Dataframe to a CSV File\n",
    "4. Reading data from an EXCEL File\n",
    "5. Writing Contents of Dataframe to an EXCEL File\n",
    "6. Reading data from a JSON File\n",
    "7. Writing Contents of Dataframe to a JSON File\n",
    "8. Reading and Writing with SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d4c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install this library in Jupyter notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__ , pd.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74b937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4e943a",
   "metadata": {},
   "source": [
    "## 1. Reading from CSV/TSV Files\n",
    ">**CSV**: A text file in which the values are separated by a comma or a tab character is called a CSV or a TSV file. Each line of the file is a data record and each record consists of one or more fields, separated by a specific character called separator. A CSV/TSV file is typically used to store tabular data (numbers and text), in which each line will have the same number of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d81fe",
   "metadata": {},
   "source": [
    "### a. Reading a  Simple CSV File\n",
    "The `pd.read_csv()` method is used to read a comma-separated file into a DataFrame.\n",
    "```\n",
    "pd.read_csv(fname, delimiter=None, header='infer', skiprows=None , nrows=None , usecols=None,  footer='',...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/classmarks.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5863995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The `read_csv`, by default assumes that the file contains comma separated values, \n",
    "# and the first row of the file conatins names of columns, which will be taken as column labels\n",
    "df = pd.read_csv('datasets/classmarks.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0945b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a190256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8e68f05",
   "metadata": {},
   "source": [
    "**The `df.head(N)` method is used to select/display first `N` rows, based on `position`, i.e., the integer value corresponding to the position of the row (from 0 to n-1). The default value of `N` is 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab86207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e5255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For negative values of n, this method returns all rows except the last `n` rows, equivalent to df[:-n].\n",
    "# The df has a total of 50 rows, so the following will return first 2 rows\n",
    "df.head(-48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8592e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a20bcc0",
   "metadata": {},
   "source": [
    "**The `df.tail(N)` method is used to select/display last `N` rows, based on `position`, i.e., the integer value corresponding to the position of the row (from 0 to n-1). The default value of `N` is 5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tail() method is useful for quickly verifying data, after sorting or appending rows.\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03574cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For negative values of `n`, this function returns all rows except the first `n` rows, equivalent to df[n:]\n",
    "# The df has a total of 50 rows, so the following will return last 3 rows\n",
    "df.tail(-46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599814b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd02f713",
   "metadata": {},
   "source": [
    "**The `df.sample()` method returns a specified number of random rows. This method returns 1 row if a number is not specified.The column names will also be returned, in addition to the sample rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d805f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa28bae8",
   "metadata": {},
   "source": [
    "### b.Reading a CSV File having a Delimter, other than Comma\n",
    "- By default, the `read_csv()` expect comma as seperator. But if the CSV file has some other seperator or delimiter like (semi-collon or tab), it will raise an error.\n",
    "- To handler the issue we need to pass specific value to the `delimiter` argument of `read_csv()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5650685",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/classmarkswithtab.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarkswithtab.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b427ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarkswithtab.csv', delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d94b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7228943",
   "metadata": {},
   "source": [
    "### c. Reading a CSV File not having Column Labels\n",
    "- By default the `read_csv()` method assume the first row of the file will contain column labels\n",
    "- If this is not the case, i.e., the file do not contain column labels rather data, it will be dealt as column label\n",
    "- Understand this in following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/classmarkswithoutcollabels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be736d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarkswithoutcollabels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a78813",
   "metadata": {},
   "source": [
    "**To read such files, you have to pass the parameter `header=None` to the `read_csv()` method as shown below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d228941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarkswithoutcollabels.csv', header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb895f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9783830",
   "metadata": {},
   "source": [
    "**Now if you want to assign new column labels to make them more understandable, you can assign the list of column labels to the `columns` attribute of the dataframe object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404229bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['rollno', 'gender', 'group', 'age', 'math', 'english', 'urdu']\n",
    "df.columns = col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f907c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf135e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736ff36e",
   "metadata": {},
   "source": [
    "### d. Reading a CSV File having Comments in the beginning\n",
    "- You may get an error while reading a CSV file because someone may have added few comments on the top of the file. In pandas we can still read the data set by skipping few rows from the top.\n",
    "- To deal with the ParseError, open the csv file in the text editor and check if you have some comments on the top.\n",
    "- If yes, then count the number of rows to skip.\n",
    "- While reading file, pass the parameter **skiprows = n** (number of rows in the beginninghaving comments to skip)\n",
    "- While reading file, pass the parameter **skipfooter = n** (number of rows at the end having comments to skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca9ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/classmarkswithtopcomments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a csv file having 3 comments lines in the beginning.\n",
    "df = pd.read_csv('datasets/classmarkswithtopcomments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc580e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try reading a csv file having 3 comments lines in the beginning.\n",
    "df = pd.read_csv('datasets/classmarkswithtopcomments.csv', skiprows=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad9283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "255294ba",
   "metadata": {},
   "source": [
    "### e. Reading a portion of CSV File in a Dataframe\n",
    "- Suppose the dataset inside the csv file is too big and you don't want to spend that much time for reading that data\n",
    "- Or might be your system crashes, when you try to load that much data\n",
    "- Solution is read\n",
    "    - Specific number of rows by passing `nrows` parameter to `read_csv()` method\n",
    "    - Specific number of columns by passing `usecols` parameter to `read_csv()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ed4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read just 10 rows from the csv file by passing the number of rows to read to `nrows` argument\n",
    "df = pd.read_csv('datasets/classmarks.csv', nrows=10)\n",
    "df.shape\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79166f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ad23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read specific columns from the csv file by passing a list of column names to `usecols` argument\n",
    "df = pd.read_csv('datasets/classmarks.csv', usecols= ['rollno', 'group','english'])\n",
    "df.shape\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf25640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ofcourse you can use both the parameters at the same time\n",
    "df = pd.read_csv('datasets/classmarks.csv', nrows= 7, usecols= ['rollno', 'group','english'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2470e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee98254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a24ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aff77179",
   "metadata": {},
   "source": [
    "## 2. Reading a CSV File from a Remote System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]..... \n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddc381",
   "metadata": {},
   "source": [
    "### a. Reading a CSV file from GitHub Gist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218b2e9",
   "metadata": {},
   "source": [
    "The `data1.csv` file actually resides on my GitHub Gist at following URL:\n",
    "https://raw.githubusercontent.com/bsef19m521/Introduction-to-Data-Analyst-and-Data-Science/master/Module%20no%2002-%20Python%20for%20Data%20Scientists/02%20-%20Pandas%20for%20Data%20Scientists/datasets/people.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cae0a2",
   "metadata": {},
   "source": [
    "[Bitly.ws](http://bitly.ws/) is a URL shortening service that I have used to create a short link for easy usage in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"http://bitly.ws/tgCj\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a3906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f312831d",
   "metadata": {},
   "source": [
    "### b. Reading a CSV file from a Google Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278b2d6e",
   "metadata": {},
   "source": [
    "\n",
    "- Google sheet url: https://docs.google.com/spreadsheets/d/1l-bh4Mga8JW3yvO0Cfr3P3E6_EpdIXH4yyvS6FOoZVI/edit#gid=212220603- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309392fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetID = '1l-bh4Mga8JW3yvO0Cfr3P3E6_EpdIXH4yyvS6FOoZVI'\n",
    "sheetName = 'sheet1'\n",
    "URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(sheetID, sheetName)\n",
    "\n",
    "df = pd.read_csv(URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3043328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da021170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bec93fe",
   "metadata": {},
   "source": [
    "## 3. Writing Contents of Dataframe to a CSV File\n",
    "- The `pd.to_csv()` method is used to write the contents of a dataframe (with indices) to a CSV file.\n",
    "- The only required argument is the file path.\n",
    "- For details see help page or python documents (link given above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87862682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_csv('datasets/classmarks.csv')\n",
    "df_class.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a8515",
   "metadata": {},
   "source": [
    ">- Let us create a new dataframe from above dataframe containing records of only group B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d35cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_class['group'] == 'group B')\n",
    "mask.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519347c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB = df_class.loc[mask]\n",
    "df_class_groupB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d92b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB.to_csv('datasets/classmarksgroupB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4da09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarksgroupB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c378d68",
   "metadata": {},
   "source": [
    ">To avoid writing the row indices column inside the file pass `index=False` argument to `to_csv()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b286a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_groupB.to_csv('datasets/classmarksgroupB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d69405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/classmarksgroupB.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb77253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc33cd11",
   "metadata": {},
   "source": [
    "## 4. I/O with EXCEL Files\n",
    ">**XLSX**: XLSX is a Microsoft Excel Open XML file format. It also comes under the Spreadsheet file format. It is an XML-based file format created by Microsoft Excel. In XLSX data is organized under the cells and columns in a sheet. Each XLSX file may contain one or more sheets. So a workbook can contain multiple sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xlrd xlwt openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1d092",
   "metadata": {},
   "source": [
    "### a. Reading a Simple Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf3d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(io='datasets/classmarks.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430bd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a08102cc",
   "metadata": {},
   "source": [
    "### b. Reading an Excel File having Comments in the beginning\n",
    "- You may get an error while reading an Excel file because someone may have added few comments on the top of the file. In pandas we can still read the data set by skipping few rows from the top.\n",
    "- To deal with the ParseError, open the Excel file in MS EXCEL and check if you have some comments on the top.\n",
    "- If yes, then count the number of rows to skip.\n",
    "- While reading file, pass the parameter **skiprows = n** (number of rows in the beginning having comments to skip)\n",
    "- While reading file, pass the parameter **skipfooter = n** (number of rows at the end having comments to skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664c762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following file has three lines of comments in the beginning of the file.\n",
    "df = pd.read_excel(io='datasets/classmarkswithcomments.xlsx')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60968a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cccdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following file has three lines of comments in the beginning of the file.\n",
    "df = pd.read_excel(io='datasets/classmarkswithcomments.xlsx',skiprows=3)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcc587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff5b811",
   "metadata": {},
   "source": [
    "### c. Reading Excel Workbook with Multiple Sheets\n",
    "- By default `pd.read_excel()` function read only the first sheet.\n",
    "- What if we want to read an Excel file having multiple sheets.\n",
    "- The `big_mart_sales_with_multiple_sheets.xlsx` is a workbook that contains three sheets for different years data. The sheet names are 1985, 1987, and 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e857867",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx')\n",
    "# if you check/view the data you can see, it only contains the data of first excel sheet (for the year 1985)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7966ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1985 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1985')\n",
    "df_1987 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1987')\n",
    "df_1997 = pd.read_excel('datasets/big_mart_sales_with_multiple_sheets.xlsx',sheet_name='1997')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sheet1 : \")\n",
    "df_1985.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cf540",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sheet2 : \")\n",
    "df_1987.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sheet2 : \")\n",
    "df_1997.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdad44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590ee34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "229e0221",
   "metadata": {},
   "source": [
    "## 5. Writing Contents of Dataframe to an EXCEL File\n",
    "- The `pd.to_excel()` method is used to write the contents of a dataframe (with indices) to an Excel file.\n",
    "- The only required argument is the file path.\n",
    "- For details see help page or python documents (link given above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30e9d9",
   "metadata": {},
   "source": [
    ">- Let us create a new single dataframe after concatenating all the above three dataframes using `pd.concat()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a30fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated = pd.concat(objs=[df_1985, df_1987, df_1997])\n",
    "\n",
    "df_concatenated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d1c9f",
   "metadata": {},
   "source": [
    "**Note the total number of rows in this dataframe equals to `1463+932+930 = 3325`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can store the concatenated data inside your dataframe into a single Excel file\n",
    "# You can mention the argument `index= false` for not storing row indices (0, 1,2,3,... in the Excel file.\n",
    "\n",
    "df_concatenated.to_excel(excel_writer='temp.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec95f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us verify\n",
    "data = pd.read_excel(io='temp.xlsx')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a845bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f84a0f6",
   "metadata": {},
   "source": [
    "## 6. I/O with JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219e7d6",
   "metadata": {},
   "source": [
    ">**JSON**: JavaScript Object Notation is a text-based open standard file format that uses human-readable text consisting of attribute–value pairs and arrays. It is a data interchange format that is used to store and transfer the data via Internet, primarily between a web client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7f1cf8",
   "metadata": {},
   "source": [
    "## a. Reading a Simple JSON File\n",
    "#### To view content of any json file , visit this [website](https://jsoneditoronline.org/#left=local.yoyezu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install SQLAlchemy psycopg2-binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/simple.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf34ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json file using read_json method of pandas library\n",
    "df = pd.read_json('datasets/simple.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc074c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55cdd441",
   "metadata": {},
   "source": [
    "### b. Reading JSON File having each record in a separate line\n",
    "- Some of the json files are written as records i.e each json line is a separate json object. For example:\n",
    "```\n",
    "{ 'name' : 'Ahsan', 'roll_no' : '100' } # line 1\n",
    "{ 'name' : 'Ayesha' , 'roll_no' : '101' } # line 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673fc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat datasets/simple_records.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read such file you need to pass `lines=True` to the `read_json()` method of dataframe\n",
    "df = pd.read_json('datasets/simple_records.json',lines=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff918dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abc6869",
   "metadata": {},
   "source": [
    "## 7. Writing Contents of Dataframe to a JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('datasets/temp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a566ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('datasets/temp.json')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4c4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb1d10b",
   "metadata": {},
   "source": [
    "## 8. Reading and writing with SQL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ae03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all we install mysql.connector on our machine\n",
    "!pip install mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second, we import mysql.connector to create connection object\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec63d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third we create our connection object\n",
    "conn = mysql.connector.connect(host='localhost',user='root',password='Pucit12345#',database='ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will execute our query\n",
    "df = pd.read_sql_query(\"SELECT * FROM DataTable\",conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67fe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317cfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221242f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77bea64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be82df5",
   "metadata": {},
   "source": [
    "## Check Your Concepts:\n",
    "- What is Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f24837",
   "metadata": {},
   "source": [
    "# Pandas - Assignment no 04\n",
    "- Here is link of [Pandas - Assignment no 04]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc95d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f32e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
